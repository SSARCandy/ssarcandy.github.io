<!DOCTYPE html><html lang="zh"><head><link rel="manifest" href="/manifest.json"><meta charset="utf-8"><title>Build a High Performance Computing Cluster on GCP | SSARCandy's Blog</title><meta name="google-site-verification" content="uUti8Shw9zIz5j2Rs_nwYT9VusmIOXijBuf2bBNYm78"><meta http-equiv="Cache-control" content="public"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#673AB7"><meta name="keywords" content="unix,slurm,note"><meta name="description" content="敝司長久以來都是自建 Cluster 來做為日常運算資源使用的，長時間一直都被擴充性、I/O 效能所卡住，若是卡在運算資源不夠光是採買新機器動輒要幾個月；被 share storage 的 I/O 效能卡住更慘，整個系統會慢到爆 job 都卡住…所以我就在想有沒有辦法在雲上建立這種高效能運算叢集，想動態擴張幾台就幾台，再加上我相信無論是 AWS, GCP 等等大平台所提供的 NFS 服務應該都差不"><meta property="og:type" content="article"><meta property="og:title" content="Build a High Performance Computing Cluster on GCP"><meta property="og:url" content="https://ssarcandy.tw/2020/04/22/Build-a-High-Performance-Computing-Cluster-on-GCP/index.html"><meta property="og:site_name" content="SSARCandy's Blog"><meta property="og:description" content="敝司長久以來都是自建 Cluster 來做為日常運算資源使用的，長時間一直都被擴充性、I/O 效能所卡住，若是卡在運算資源不夠光是採買新機器動輒要幾個月；被 share storage 的 I/O 效能卡住更慘，整個系統會慢到爆 job 都卡住…所以我就在想有沒有辦法在雲上建立這種高效能運算叢集，想動態擴張幾台就幾台，再加上我相信無論是 AWS, GCP 等等大平台所提供的 NFS 服務應該都差不"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://ssarcandy.tw/img/2020-04-22/2.png"><meta property="og:image" content="https://ssarcandy.tw/img/2020-04-22/1.png"><meta property="og:image" content="https://ssarcandy.tw/img/2020-04-22/3.png"><meta property="og:image" content="https://ssarcandy.tw/img/2020-04-22/4.png"><meta property="og:image" content="https://ssarcandy.tw/img/logo.png"><meta property="article:published_time" content="2020-04-21T19:26:24.000Z"><meta property="article:modified_time" content="2020-07-15T04:24:08.538Z"><meta property="article:author" content="許書軒"><meta property="article:tag" content="unix"><meta property="article:tag" content="slurm"><meta property="article:tag" content="note"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://ssarcandy.tw/img/2020-04-22/2.png"><link rel="alternative" href="/atom.xml" title="SSARCandy's Blog" type="application/atom+xml"><meta name="summary" content="敝司長久以來都是自建 Cluster 來做為日常運算資源使用的，長時間一直都被擴充性、I/O 效能所卡住，若是卡在運算資源不夠光是採買新機器動輒要幾個月；被 share storage 的 I/O 效能卡住更慘，整個系統會慢到爆 job 都卡住…所以我就在想有沒有辦法在雲上建立這種高效能運算叢集，想動態擴張幾台就幾台，再加上我相信無論是 AWS, GCP 等等大平台所提供的 NFS 服務應該都差不到哪裡去吧…? "><meta name="Description" content="ssarcandy's blog. There is always more than one solution."><link rel="shortcut icon" href="/img/favicon.ico"><link rel="stylesheet" href="/css/style.css"><link async href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"><link rel="manifest" href="/web-app-manifest.json"><meta name="generator" content="Hexo 4.1.1"><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG]>svg a{fill:#00f;stroke:#00f}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style><style>mjx-container[jax=SVG]{direction:ltr}mjx-container[jax=SVG]>svg{overflow:visible}mjx-container[jax=SVG]>svg a{fill:#00f;stroke:#00f}mjx-container[jax=SVG][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=SVG][justify=left]{text-align:left}mjx-container[jax=SVG][justify=right]{text-align:right}g[data-mml-node=merror]>g{fill:red;stroke:red}g[data-mml-node=merror]>rect[data-background]{fill:#ff0;stroke:none}g[data-mml-node=mtable]>line[data-line]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>rect[data-frame]{stroke-width:70px;fill:none}g[data-mml-node=mtable]>.mjx-dashed{stroke-dasharray:140}g[data-mml-node=mtable]>.mjx-dotted{stroke-linecap:round;stroke-dasharray:0,140}g[data-mml-node=mtable]>svg{overflow:visible}[jax=SVG] mjx-tool{display:inline-block;position:relative;width:0;height:0}[jax=SVG] mjx-tool>mjx-tip{position:absolute;top:0;left:0}mjx-tool>mjx-tip{display:inline-block;padding:.2em;border:1px solid #888;font-size:70%;background-color:#f8f8f8;color:#000;box-shadow:2px 2px 5px #aaa}g[data-mml-node=maction][data-toggle]{cursor:pointer}mjx-status{display:block;position:fixed;left:1em;bottom:1em;min-width:25%;padding:.2em .4em;border:1px solid #888;font-size:90%;background-color:#f8f8f8;color:#000}foreignObject[data-mjx-xml]{font-family:initial;line-height:normal;overflow:visible}.MathJax path{stroke-width:3}mjx-container[display=true]{overflow:auto hidden}mjx-container[display=true]+br{display:none}</style></head><body><div id="loading" class="active"></div><nav id="menu" class="hide"><div class="inner flex-row-vertical"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off"><i class="icon icon-lg material-icons">close</i></a><div class="brand-wrap"><div class="brand"><a href="/about" class="avatar"><img alt="ssarcandy" src="/img/logo.png"></a><hgroup class="introduce"><div class="mail">There is always more than one solution.</div></hgroup></div></div><ul class="nav flex-col"><li class="waves-block waves-effect" style="line-height:44px;height:44px;padding:0 0"><a href="/about"><i class="material-icons icon icon-lg">person</i> <span>About</span></a></li><li class="waves-block waves-effect" style="line-height:44px;height:44px;padding:0 0"><a href="/"><i class="material-icons icon icon-lg">description</i> <span>Post</span></a></li><li class="waves-block waves-effect" style="line-height:44px;height:44px;padding:0 0"><a href="/archives"><i class="material-icons icon icon-lg">view_list</i> <span>Archives</span></a></li><li class="waves-block waves-effect" style="line-height:44px;height:44px;padding:0 0"><a href="/projects"><i class="material-icons icon icon-lg">code</i> <span>Projects</span></a></li><li class="waves-block waves-effect" style="line-height:44px;height:44px;padding:0 0"><a href="https://github.com/SSARCandy" target="_blank" rel="noopener"><i class="icon icon-lg icon-github"></i> <span>Github</span></a></li></ul><footer class="footer"><p>Total visitors: 53,773</p><p>SSARCandy © 2016 - 2020</p><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-2x icon-rss-square"></i></a></footer></div></nav><main id="main"><header class="top-header" id="header"><div class="flex-row"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle"><i class="icon icon-lg material-icons">menu</i></a><div class="flex-col header-title ellipsis">Build a High Performance Computing Cluster on GCP</div><div class="search-wrap" id="search-wrap"><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back"><i class="icon icon-lg material-icons">navigate_before</i> </a><input type="text" id="key" class="search-input" aria-label="search-box" autocomplete="off" placeholder="Keywords"> <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search"><i class="icon icon-lg material-icons">search</i></a></div><a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-share"><i class="icon icon-lg material-icons">share</i></a></div></header><header class="content-header"><div class="container"><h1 class="author">Build a High Performance Computing Cluster on GCP</h1><h5 class="subtitle"><time datetime="2020-04-21T19:26:24.000Z" itemprop="datePublished" class="page-time">Apr 22 2020</time></h5></div></header><aside class="post-widget" id="post-widget"><nav class="post-toc-wrap" id="post-toc"><h4>Contents</h4><ol class="post-toc"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Create-a-Share-Storage"><span class="post-toc-text">Create a Share Storage</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Setup-Slurm-Cluster"><span class="post-toc-text">Setup Slurm Cluster</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Deploy-amp-Test-It"><span class="post-toc-text">Deploy & Test It</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Reference"><span class="post-toc-text">Reference</span></a></li></ol></nav></aside><div class="container body-wrap" id="body-wrap"><article id="post-Build-a-High-Performance-Computing-Cluster-on-GCP" class="article article-type-post" itemprop="blogPost"><div class="post-meat flex-row"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/note/" rel="tag">note</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/slurm/" rel="tag">slurm</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/unix/" rel="tag">unix</a></li></ul></div><div class="post-meat" style="color:grey;font-size:13px"><i class="icon icon-sm icon-eye" aria-hidden="true"></i> 362</div><div class="post-body"><div class="post-main"><div class="post-content" id="post-content" itemprop="postContent"><p>敝司長久以來都是自建 Cluster 來做為日常運算資源使用的，長時間一直都被擴充性、I/O 效能所卡住，若是卡在運算資源不夠光是採買新機器動輒要幾個月；被 share storage 的 I/O 效能卡住更慘，整個系統會慢到爆 job 都卡住…<br>所以我就在想有沒有辦法在雲上建立這種高效能運算叢集，想動態擴張幾台就幾台，再加上我相信無論是 AWS, GCP 等等大平台所提供的 NFS 服務應該都差不到哪裡去吧…?</p><a id="more"></a><p>本文旨在在 Google Cloud Platform 上建立由 Slurm<sup>[1]</sup> 管理的運算叢集，並且也建立一個 NFS 自動掛載在所有 compute nodes 上面供大家讀取及寫入。</p><p>在開始之前要先釐清這個 cluster 需要的東西，基本上是下列：</p><ul><li>A client VM</li><li>Slurm controller</li><li>N 個 Slurm computing nodes</li><li>NFS that mount on all computing nodes</li></ul><p>整體圖大概長這樣，基本上參考 google 的架構<sup>[2]</sup>，只是加上一個 NFS</p><div><img src="/img/2020-04-22/2.png" alt="架構圖。Client VM 也需要掛載 NFS" data-action="zoom" class="photozoom"> <span class="zoom-initial-caption">架構圖。Client VM 也需要掛載 NFS</span></div><h2 id="Create-a-Share-Storage"><a href="#Create-a-Share-Storage" class="headerlink" title="Create a Share Storage"></a>Create a Share Storage</h2><p>首先先來建立一個儲存空間來當作 NFS ，用於掛載在所有 Nodes 上，這樣才可以在任何地方存取同樣的資料，我這邊選用 Google Filestore 因為他的 I/O 會比一般 Google 的 pd-standard 或 pd-ssd 來的好<sup>[3]</sup></p><p>建立這個就不太需要介紹了，就跑去 GCP console 案案案就好了，其中一個要注意的是 authorized VPC network 如果沒特別需要，可以選 default 會比較簡單。</p><div><img src="/img/2020-04-22/1.png" alt="案案案就會得到這個" data-action="zoom" class="photozoom"> <span class="zoom-initial-caption">案案案就會得到這個</span></div><h2 id="Setup-Slurm-Cluster"><a href="#Setup-Slurm-Cluster" class="headerlink" title="Setup Slurm Cluster"></a>Setup Slurm Cluster</h2><p>接下來要來佈屬 Slurm controller, compute nodes, client VM 到 GCP 上，這邊其實已經有整個模板了，<a href="https://github.com/SchedMD/slurm-gcp" target="_blank" rel="noopener">github 連結</a>。<br>這個可以直接用 <code>gcloud</code> 佈署，但在此之前需要先改改 config ，主要要改的是 <code>slurm-cluster.yaml</code></p><ul><li>cluster_name: 愛取啥取啥</li><li>zone: 既然在台灣就選 <code>asia-east1-b</code></li><li>vpc_net: 這要填 <code>default</code>，不填的話會自動建立 <code>{cluster_name}-network</code> 的 VPC</li><li>vpc_subnet: 填 default 吧</li><li>controller_machine_type: 如果 compute node 打算超過 100 台的話可以選好一點</li><li>network_storage: 這邊要掛載剛剛建立的 nfs</li></ul><p>其他就參考以下吧</p><figure class="highlight yaml"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">imports:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">path:</span> <span class="string">slurm.jinja</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">resources:</span></span><br><span class="line"><span class="bullet">-</span> <span class="attr">name:</span> <span class="string">slurm-cluster</span></span><br><span class="line">    <span class="attr">type:</span> <span class="string">slurm.jinja</span></span><br><span class="line">    <span class="attr">properties:</span></span><br><span class="line">    <span class="attr">cluster_name:</span> <span class="string">cloud-slurm</span></span><br><span class="line">    <span class="attr">zone:</span> <span class="string">asia-east1-b</span></span><br><span class="line">    <span class="attr">vpc_net:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">vpc_subnet:</span> <span class="string">default</span></span><br><span class="line">    <span class="attr">controller_machine_type:</span> <span class="string">n1-standard-8</span></span><br><span class="line">    <span class="attr">controller_disk_type:</span> <span class="string">pd-standard</span></span><br><span class="line">    <span class="attr">controller_disk_size_gb:</span> <span class="number">20</span></span><br><span class="line">    <span class="attr">login_machine_type:</span> <span class="string">n1-standard-2</span></span><br><span class="line">    <span class="attr">network_storage:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">server_ip:</span> <span class="string"><filestore</span> <span class="string">ip></span></span><br><span class="line">        <span class="attr">remote_mount:</span> <span class="string">/slurm_nfs</span></span><br><span class="line">        <span class="attr">local_mount:</span> <span class="string">/j</span></span><br><span class="line">        <span class="attr">fs_type:</span> <span class="string">nfs</span></span><br><span class="line">    <span class="attr">compute_image_machine_type:</span> <span class="string">n1-standard-2</span></span><br><span class="line">    <span class="attr">ompi_version:</span> <span class="string">v3.1.x</span></span><br><span class="line">    <span class="attr">partitions:</span></span><br><span class="line">        <span class="bullet">-</span> <span class="attr">name:</span> <span class="string">fast</span></span><br><span class="line">        <span class="attr">machine_type:</span> <span class="string">n1-standard-2</span></span><br><span class="line">        <span class="attr">max_node_count:</span> <span class="number">100</span></span><br><span class="line">        <span class="attr">zone:</span> <span class="string">asia-east1-b</span></span><br><span class="line">        <span class="attr">vpc_subnet:</span> <span class="string">default</span></span><br></pre></td></tr></tbody></table></figure><p>另外一個要改的是 <code>scripts/startup.sh</code> ，這個 script 是 VM 啟動會執行的，由於我們用到 NFS 所以要安裝 nfs package:</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># scripts/startup.sh</span></span><br><span class="line">  </span><br><span class="line">PACKAGES=(</span><br><span class="line">        <span class="string">'bind-utils'</span></span><br><span class="line">        <span class="comment"># ... skip</span></span><br><span class="line">        <span class="string">'yum-utils'</span></span><br><span class="line">        <span class="string">'nfs-utils'</span> <span class="comment"># we need this one for mount nfs</span></span><br><span class="line">    )</span><br></pre></td></tr></tbody></table></figure><p>我個人認為最大的雷就是 filestore 跟 slurm cluster 必須在同一個 VPC 才能掛載，然後這個 slurm template 不指定 vpc 他會幫你建一個 (不是用 default)，所以我一開始搞一直不同 vpc 掛不起來…</p><h2 id="Deploy-amp-Test-It"><a href="#Deploy-amp-Test-It" class="headerlink" title="Deploy & Test It"></a>Deploy & Test It</h2><p>設定通通解決後接下來就是佈署上 GCP 了，基本上透過 gcloud 就可以了:<br>這邊可以 clone 我改過的設定檔 (跟上面說的設定一樣)，記得要填 nfs IP</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ git <span class="built_in">clone</span> https://github.com/SSARCandy/slurm-gcp.git</span><br><span class="line">$ <span class="built_in">cd</span> slurm-gcp</span><br><span class="line">$ gcloud deployment-manager deployments create gcp-slurm --config slurm-cluster.yaml</span><br><span class="line">Waiting <span class="keyword">for</span> create [operation-5a3cd5941e0b1-f13e780b-ba00af15]...<span class="keyword">done</span>.</span><br><span class="line">Create operation operation-5a3cd5941e0b1-f13e780b-ba00af15 completed successfully.</span><br><span class="line">NAME                           TYPE                 STATE      ERRORS  INTENT</span><br><span class="line">cloud-slurm-asia-east1-router  compute.v1.router    COMPLETED  []</span><br><span class="line">cloud-slurm-compute-0-image    compute.v1.instance  COMPLETED  []</span><br><span class="line">cloud-slurm-controller         compute.v1.instance  COMPLETED  []</span><br><span class="line">cloud-slurm-login0             compute.v1.instance  COMPLETED  []</span><br></pre></td></tr></tbody></table></figure><p>接下來要等一下大概五分鐘，因為要建立一個 compute node 的 image，之後要自動擴展 compute node 時使用。</p><div><img src="/img/2020-04-22/3.png" alt="完成後可以在 console 上看到" data-action="zoom" class="photozoom"> <span class="zoom-initial-caption">完成後可以在 console 上看到</span></div><p>待一切就序之後就可以登入試試，可以看到 <code>slurm_nfs</code> 也有掛載在上面：</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ gcloud compute ssh cloud-slurm-login0 --zone=asia-east1-b</span><br><span class="line">$ df -h</span><br><span class="line">Filesystem                         Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs                           3.6G     0  3.6G   0% /dev</span><br><span class="line">tmpfs                              3.6G     0  3.6G   0% /dev/shm</span><br><span class="line">tmpfs                              3.6G  8.5M  3.6G   1% /run</span><br><span class="line">tmpfs                              3.6G     0  3.6G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda2                           20G  2.8G   18G  15% /</span><br><span class="line">/dev/sda1                          200M   12M  189M   6% /boot/efi</span><br><span class="line">cloud-slurm-controller:/home        20G  4.4G   16G  22% /home</span><br><span class="line">cloud-slurm-controller:/apps        20G  4.4G   16G  22% /apps</span><br><span class="line">cloud-slurm-controller:/etc/munge   20G  4.4G   16G  22% /etc/munge</span><br><span class="line">10.173.83.218:/slurm_nfs           2.5T  9.9G  2.4T   1% /j</span><br><span class="line">tmpfs                              732M     0  732M   0% /run/user/1993390025</span><br></pre></td></tr></tbody></table></figure><p>利用 <code>sinfo</code> 可以查看 slurm cluster status，有一百台等著被使用。這一百台都是假的，要等到有人真的發 job 才會建立，然後閒置太久就會被關掉，是個很省錢的方式呢～</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ sinfo </span><br><span class="line">PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST</span><br><span class="line">fast*        up   infinite    100  idle~ cloud-slurm-compute-0-[0-99]</span><br></pre></td></tr></tbody></table></figure><div><img src="/img/2020-04-22/4.png" alt="發送 jobs 時才會動態建立 computing nodes，閒置過久會刪掉" data-action="zoom" class="photozoom"> <span class="zoom-initial-caption">發送 jobs 時才會動態建立 computing nodes，閒置過久會刪掉</span></div><p>試試看發很多個會寫檔到 NFS 的 job，先建立個 <code>slurm_filewriter.sh</code>，這個檔案會執行寫入 1GB 的資料到 NFS 裡。</p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment">#SBATCH --job-name=io-performannce</span></span><br><span class="line"><span class="comment">#SBATCH --output=out_%j</span></span><br><span class="line"><span class="comment">#SBATCH --ntasks=1</span></span><br><span class="line"><span class="comment">#SBATCH --ntasks-per-node=1</span></span><br><span class="line"><span class="comment">#SBATCH --cpus-per-task=1</span></span><br><span class="line">f=`hostname`</span><br><span class="line">rand=`head /dev/urandom | tr -dc A-Z | head -c 5 ; <span class="built_in">echo</span> <span class="string">''</span>`</span><br><span class="line">sync && dd <span class="keyword">if</span>=/dev/zero of=/j/root/testfile_<span class="variable">${f}</span>_<span class="variable">${rand}</span> bs=10M count=100 oflag=direct 2>&1 | cat</span><br></pre></td></tr></tbody></table></figure><p>然後透過 sbatch 發 jobs，關於 slurm 用法可參考這個<a href="https://slurm.schedmd.com/pdfs/summary.pdf" target="_blank" rel="noopener">小抄</a></p><figure class="highlight sh"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># send 5 parallel jobs that write file to NFS</span></span><br><span class="line">$ <span class="keyword">for</span> i <span class="keyword">in</span> `seq 5`; <span class="keyword">do</span> sbatch slurm_filewriter.sh ; <span class="keyword">done</span></span><br><span class="line">Submitted batch job 203</span><br><span class="line">Submitted batch job 204</span><br><span class="line">Submitted batch job 205</span><br><span class="line">Submitted batch job 206</span><br><span class="line">Submitted batch job 207</span><br><span class="line"> </span><br><span class="line"><span class="comment"># after squeue shows no job, can see that files has been written to NFS</span></span><br><span class="line">$ ls -1 /j/root</span><br><span class="line">testfile_cloud-slurm-compute-0-0_CIDCR</span><br><span class="line">testfile_cloud-slurm-compute-0-0_GKCQM</span><br><span class="line">testfile_cloud-slurm-compute-0-0_XDIAQ</span><br><span class="line">testfile_cloud-slurm-compute-0-0_XJHTW</span><br><span class="line">testfile_cloud-slurm-compute-0-2_VPSEW</span><br></pre></td></tr></tbody></table></figure><p>至此整個 slurm cluster 就佈署到 GCP 上了，可以開始開心使用啦～<br>這樣的優點包含可以無上限擴充運算資源，再也不用等待！<br>NFS I/O 根據我的測試也是完勝自架的分散式儲存系統！<br>壞處則是可能也許會有些貴…(?)</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] <a href="https://slurm.schedmd.com/documentation.html" target="_blank" rel="noopener">https://slurm.schedmd.com/documentation.html</a><br>[2] <a href="https://codelabs.developers.google.com/codelabs/hpc-slurm-on-gcp" target="_blank" rel="noopener">https://codelabs.developers.google.com/codelabs/hpc-slurm-on-gcp</a><br>[3] <a href="https://cloud.google.com/compute/docs/disks" target="_blank" rel="noopener">https://cloud.google.com/compute/docs/disks</a></p><hr><p><strong>雜談</strong></p><p>噫！好了！我畢業了！</p></div><hr><div class="article related-post-label">Related Posts</div><ul style="padding:0"><li class="related-post-list"><a href="/2019/03/16/Setup-Slurm-Cluster/" class="post-title related-post">Setup Slurm Cluster</a></li><li class="related-post-list"><a href="/2017/03/20/Setup-x11-forwarding-on-Debian/" class="post-title related-post">Setup x11 forwarding on Debian</a></li><li class="related-post-list"><a href="/2019/08/12/Ways-to-Access-Internal-Network/" class="post-title related-post">Ways to Access Internal Network</a></li><li class="related-post-list"><a href="/2017/04/29/migrate-to-gmail-migration-strategy/" class="post-title related-post">Migrate mail server to Gmail - migration strategy</a></li><li class="related-post-list"><a href="/2017/04/23/migrate-to-gmail-using-migration-tool/" class="post-title related-post">Migrate mail server to Gmail - using migration tool</a></li></ul><script data-ad-client="ca-pub-1532347766435780" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script><ins class="adsbygoogle" style="display:block;text-align:center" data-ad-layout="in-article" data-ad-format="fluid" data-ad-client="ca-pub-1532347766435780" data-ad-slot="3786040804"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script><section id="comments"><div id="disqus_thread"></div><script>!function(){var t=document,e=t.createElement("script");e.src="https://ssarcandy.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" target="_blank" rel="noopener">comments powered by Disqus.</a></noscript></section></div></div></article><script type="application/ld+json">{
  "@context": "http://schema.org",
  "@type": "Article",
  "mainEntityOfPage": "https://ssarcandy.tw/2020/04/22/Build-a-High-Performance-Computing-Cluster-on-GCP/",
  "headline": "Build a High Performance Computing Cluster on GCP",
  "datePublished": "Wed Apr 22 2020 03:26:24 GMT+0800 (Taipei Standard Time)",
  "dateModified": "Wed Apr 22 2020 03:26:24 GMT+0800 (Taipei Standard Time)",
  "author": "SSARCandy",
  "image": {
    "@type": "ImageObject",
    "url": "https://ssarcandy.tw"
  },
  "publisher":{ 
    "@type" : "Organization",
    "name": "SSARCandy's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://ssarcandy.tw/img/logo.png"
    }
  }     
}</script></div></main><script async src="https://www.googletagmanager.com/gtag/js?id=UA-81178870-1"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-81178870-1")</script><div class="search-panel" id="search-panel"><ul class="search-result" id="search-result"></ul></div><div class="mask" id="mask"></div><div class="global-share" id="global-share"><ul class="reset share-icons"><li class="waves-block waves-effect"><a class="share-sns" href="https://www.facebook.com/sharer/sharer.php?u=https://ssarcandy.tw/2020/04/22/Build-a-High-Performance-Computing-Cluster-on-GCP/index.html" target="_blank" rel="noopener" data-title="Facebook"><i class="icon icon-facebook"></i></a></li><li class="waves-block waves-effect"><a class="share-sns" href="https://twitter.com/intent/tweet?text=https://ssarcandy.tw/2020/04/22/Build-a-High-Performance-Computing-Cluster-on-GCP/index.html" target="_blank" rel="noopener" data-title="Twitter"><i class="icon icon-twitter"></i></a></li></ul></div><script src="/js/app.bundle.js"></script><script>"serviceWorker"in navigator&&navigator.serviceWorker.register("/sw.js?t=1594787132920").then(function(){console.log("ServiceWorker Register Successfully.")}).catch(function(e){console.error(e)})</script><script type="text/javascript">/**
 * Pure JavaScript implementation of zoom.js.
 *
 * Original preamble:
 * zoom.js - It's the best way to zoom an image
 * @version v0.0.2
 * @link https://github.com/fat/zoom.js
 * @license MIT
 *
 * This is a fork of the original zoom.js implementation by @fat.
 * Copyrights for the original project are held by @fat. All other copyright
 * for changes in the fork are held by Nishanth Shanmugham.
 *
 * Copyright (c) 2013 @fat
 * The MIT License. Copyright © 2016 Nishanth Shanmugham.
 */
!function(){"use strict";var t=function(){function t(t,e){for(var n=0;n<e.length;n++){var i=e[n];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(t,i.key,i)}}return function(e,n,i){return n&&t(e.prototype,n),i&&t(e,i),e}}();function e(t,e){if(!(t instanceof e))throw new TypeError("Cannot call a class as a function")}!function(t){var e={};function n(i){if(e[i])return e[i].exports;var o=e[i]={i:i,l:!1,exports:{}};return t[i].call(o.exports,o,o.exports,n),o.l=!0,o.exports}n.m=t,n.c=e,n.i=function(t){return t},n.d=function(t,e,i){n.o(t,e)||Object.defineProperty(t,e,{configurable:!1,enumerable:!0,get:i})},n.n=function(t){var e=t&&t.__esModule?function(){return t.default}:function(){return t};return n.d(e,"a",e),e},n.o=function(t,e){return Object.prototype.hasOwnProperty.call(t,e)},n.p="",n(n.s=3)}([function(t,e,n){n.d(e,"a",function(){return i}),n.d(e,"b",function(){return o}),n.d(e,"c",function(){return r}),n.d(e,"d",function(){return a});var i=function(){return document.documentElement.clientWidth},o=function(){return document.documentElement.clientHeight},r=function(t){var e=t.getBoundingClientRect(),n=document.documentElement,i=window;return{top:e.top+i.pageYOffset-n.clientTop,left:e.left+i.pageXOffset-n.clientLeft}},a=function(t,e,n){t.addEventListener(e,function t(i){i.target.removeEventListener(e,t),n()})}},function(t,e,n){var i=n(2),o=n(0);n.d(e,"a",function(){return g});var r=null,a=-1,s=-1,c=function(t){document.body.classList.contains("zoom-overlay-open")||(t.metaKey||t.ctrlKey?window.open(t.target.getAttribute("data-original")||t.target.src,"_blank"):t.target.width>=n.i(o.a)()-80||(u(!0),(r=new i.a(t.target,80)).zoom(),l()))},u=function(t){null!=r&&(t?r.dispose():r.close(),d(),r=null)},l=function(){document.addEventListener("scroll",m),document.addEventListener("keyup",f),document.addEventListener("touchstart",h),document.addEventListener("click",v,!0)},d=function(){document.removeEventListener("scroll",m),document.removeEventListener("keyup",f),document.removeEventListener("touchstart",h),document.removeEventListener("click",v,!0)},m=function(){-1==a&&(a=window.pageYOffset),Math.abs(a-window.pageYOffset)>=40&&u()},f=function(t){27==t.keyCode&&u()},h=function(t){var e=t.touches[0];null!=e&&(s=e.pageY,t.target.addEventListener("touchmove",p))},p=function t(e){var n=e.touches[0];null!=n&&Math.abs(n.pageY-s)>10&&(u(),e.target.removeEventListener("touchmove",t))},v=function(){u()},g=Object.create(null);g.setup=function(t){t.addEventListener("click",c)}},function(n,i,o){var r=o(0),a=function t(n,i){e(this,t),this.w=n,this.h=i},s=function(){function n(t,i){e(this,n),this.img=t,this.preservedTransform=t.style.transform,this.wrap=null,this.caption=null,this.overlay=null,this.offset=i}return t(n,[{key:"forceRepaint",value:function(){this.img.offsetWidth}},{key:"zoom",value:function(){var t=new a(this.img.naturalWidth,this.img.naturalHeight);this.wrap=document.createElement("div"),this.wrap.classList.add("zoom-img-wrap"),this.img.parentNode.insertBefore(this.wrap,this.img),this.wrap.appendChild(this.img),this.img.classList.add("zoom-img"),this.img.setAttribute("data-action","zoom-out"),this.overlay=document.createElement("div"),this.overlay.classList.add("zoom-overlay"),this.caption=document.createElement("span"),this.caption.innerHTML=this.img.getAttribute("alt"),this.caption.classList.add("zoom-caption"),this.overlay.appendChild(this.caption),document.body.appendChild(this.overlay),this.forceRepaint();var e=this.calculateScale(t);this.forceRepaint(),this.animate(e),document.body.classList.add("zoom-overlay-open")}},{key:"calculateScale",value:function(t){var e=t.w/this.img.width,n=o.i(r.a)()-this.offset,i=o.i(r.b)()-this.offset,a=t.w/t.h,s=n/i;return t.w<n&&t.h<i?e:a<s?i/t.h*e:n/t.w*e}},{key:"animate",value:function(t){var e=o.i(r.c)(this.img),n=window.pageYOffset,i=o.i(r.a)()/2,a=n+o.i(r.b)()/2,s="scale("+t+")",c="translate3d("+(i-(e.left+this.img.width/2))+"px, "+(a-(e.top+this.img.height/2))+"px, 0px)";this.img.style.transform=s,this.wrap.style.transform=c}},{key:"dispose",value:function(){null!=this.wrap&&null!=this.wrap.parentNode&&(this.img.classList.remove("zoom-img"),this.img.setAttribute("data-action","zoom"),this.wrap.parentNode.insertBefore(this.img,this.wrap),this.wrap.parentNode.removeChild(this.wrap),document.body.removeChild(this.overlay),document.body.classList.remove("zoom-overlay-transitioning"))}},{key:"close",value:function(){var t=this;document.body.classList.add("zoom-overlay-transitioning"),this.img.style.transform=this.preservedTransform,0===this.img.style.length&&this.img.removeAttribute("style"),this.wrap.style.transform="none",o.i(r.d)(this.img,"transitionend",function(){t.dispose(),document.body.classList.remove("zoom-overlay-open")})}}]),n}();i.a=s},function(t,e,n){Object.defineProperty(e,"__esModule",{value:!0});var i=n(1);document.addEventListener("DOMContentLoaded",function(){for(var t=document.querySelectorAll("img[data-action='zoom']"),e=0;e<t.length;e++)i.a.setup(t[e])})}])}();</script><style>img[data-action=zoom]{cursor:pointer;cursor:-webkit-zoom-in;cursor:-moz-zoom-in}.zoom-img,.zoom-img-wrap{position:relative;z-index:666;-webkit-transition:all .3s;-o-transition:all .3s;transition:all .3s}img.zoom-img{cursor:pointer;cursor:-webkit-zoom-out;cursor:-moz-zoom-out}.zoom-overlay{z-index:420;text-align:center;background:#fff;position:fixed;top:0;left:0;right:0;bottom:0;pointer-events:none;filter:"alpha(opacity=0)";opacity:0;-webkit-transition:opacity .3s;-o-transition:opacity .3s;transition:opacity .3s}.zoom-overlay-open .zoom-overlay{filter:"alpha(opacity=100)";opacity:1}.zoom-overlay-open,.zoom-overlay-transitioning{cursor:default}.body-wrap-zoom{width:100vw}.zoom-caption{z-index:667;bottom:10px;position:fixed;left:10px;right:10px}.zoom-initial-caption{color:#999;display:block;font-size:.9em;margin-top:.5em;position:relative;text-align:center;}</style></body></html>