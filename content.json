{"meta":{"title":"SSARCandy","subtitle":"","description":"","author":"許書軒","url":"https://ssarcandy.tw"},"pages":[{"title":"","date":"2017-02-13T16:09:25.941Z","updated":"2017-02-13T16:09:25.941Z","comments":true,"path":"web-app-manifest.json","permalink":"https://ssarcandy.tw/web-app-manifest.json","excerpt":"","text":"{\"name\":\"ssarcandy\",\"start_url\":\"/\",\"display\":\"standalone\",\"orientation\":\"natural\"}"},{"title":"About","date":"2017-02-13T16:09:25.881Z","updated":"2017-02-13T16:09:25.881Z","comments":false,"path":"about/index.html","permalink":"https://ssarcandy.tw/about/index.html","excerpt":"","text":"drflkgtkre"},{"title":"","date":"2017-02-13T16:09:25.941Z","updated":"2017-02-13T16:09:25.941Z","comments":false,"path":"tags/index.html","permalink":"https://ssarcandy.tw/tags/index.html","excerpt":"","text":""},{"title":"Projects","date":"2017-02-13T16:09:25.941Z","updated":"2017-02-13T16:09:25.941Z","comments":false,"path":"projects/index.html","permalink":"https://ssarcandy.tw/projects/index.html","excerpt":"","text":""}],"posts":[{"title":"From React to React Native","slug":"from-react-to-react-native","date":"2017-02-02T03:04:00.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2017/02/02/from-react-to-react-native/","link":"","permalink":"https://ssarcandy.tw/2017/02/02/from-react-to-react-native/","excerpt":"接觸 React 其實也一段時間了，總是嚷嚷想做個自己的 Project 但始終沒有動手開始做。最近趁著寒假終於用 React 做了個網頁小遊戲，之後也改寫成 React Native 做出 Android and iOS 的原生 app，順便把 android 版上架到 Google play 上～(iOS app store 費用太高付不起…)算是完成幾個長久以來的小小目標(?)","text":"接觸 React 其實也一段時間了，總是嚷嚷想做個自己的 Project 但始終沒有動手開始做。最近趁著寒假終於用 React 做了個 網頁小遊戲 ，之後也改寫成 React Native 做出 Android and iOS 的原生 app，順便把 android 版上架到 Google play 上～(iOS app store 費用太高付不起…) 算是完成幾個長久以來的小小目標(?) 用 React Native 做出 Android/iOS 原生 app 說真的寫好 React 版本以後要改寫成 React Native 還挺容易的，基本上要改的只有介面的部分，對應到程式碼大概就是每個 Component 中的 render()，當然還有 CSS 要改成 react-native 的 style，Animation 也不能用 CSS 來做了，這也是比較麻煩的地方。 檔案結構React 版跟 React Native 版的檔案結構其實幾乎都是差不多的，可以看下圖的對應： 左圖是 React 的檔案結構；右圖是 React Native 的檔案結構。 最大的差異是 style/ 資料夾不見了，這是因為 React Native 的 style 我都寫在 components 檔案裡面了。React 版本的 index.js 是進入點。其他檔案基本上都維持一樣的結構、React 版本定義的 components 在 react-native 版中都依舊存在。 左為 React 版；右為 React Native 版，元件完全一致。 改寫 render() 邏輯可以重用，要改的只有渲染的部分。 我在改寫的時候，反正第一步就是把 &lt;div&gt; 通通改成 &lt;View&gt; ，把包住文字的 &lt;span&gt;、&lt;div&gt; 改成 &lt;Text&gt; ，這樣大概就完成一半了吧 (?) 剩下的一半就是找找最適合的 native component ，這些可以上官方文件尋找。 改寫 Style 看似像 CSS，但又沒這麼好用，比較像是閹割版的 CSS。 React Native 的 style 是個 javascript 的物件，大概有七成可以跟 CSS 直接對應，寫法就是原本 CSS 改成 camlCase 寫，如果要寫得像 css 的 class 的話還要使用 StyleSheet.create() : 1234567891011// css.name &#123; font-size: 20px;&#125; // react nativeconst styles = StyleSheet.create(&#123; name: &#123; fontSize: 20 &#125;&#125;); 套用樣式的寫法則是直接用 style={Object} ，若要套用複合樣式，則在 style 中放一個 object array(順序有差): 1234&lt;View&gt; &lt;Text style=&#123;styles.red&#125;&gt;just red&lt;/Text&gt; &lt;Text style=&#123;[styles.red, styles.bigblue]&#125;&gt;red, then bigblue&lt;/Text&gt;&lt;/View&gt; Animation原本 React 版的動畫全都是用 css 做出來的，但這些在 React Native 中就沒辦法用了，官方有提供 Animation 相關的 API，但說實在的真的有點難搞。後來我是用某大神寫的 library react-native-animatable，比起官方提供的更好用。 Divide and Conquer 改寫要一部份一部份改比較容易，一次要全改只會要你命！ 從 React 改成 React Native 雖然好像不用費很大的功夫，但是如果想要一次到位全部改好其實還是很困難的。我這個 Project 已經是很小規模的了 (約 500 多行)，但第一次想一次到位時我花了一兩個小時還是連 build 都沒辦法成功。所以果然還是一部份一部份改起來比較輕鬆。 以我的例子而言，是先改 &lt;StatusPanel/&gt; ，因為只要會倒數就好嘛，單純了自然就比較好寫；再來改 &lt;ArrowKey/&gt; 最後才是改 &lt;QuestionList/&gt; 跟 &lt;Question/&gt; ，這樣分批改前前後後大概只花兩個小時就全部搞定了。 一些坑以及一些筆記 進入點註冊程式就好React Native 官方 example 的主程式都是寫在 index.android.js (或 .ios.js ) 裡面，個人感覺是可以把主邏輯拆出來，進入點只負責註冊程式就好: 12345import &#123; AppRegistry &#125; from 'react-native';import colorblocksRN from './src/app'; // 主程式 component // 進入點只做 register 的動作AppRegistry.registerComponent('colorblocksRN', () =&gt; colorblocksRN); iOS 樣式有差 即使用一模一樣的 code，iOS 跑起來樣式跟 android 的還是有差別，這我也不知道為甚麼，反正最後記得針對 iOS 的樣式再修改修改。 不能 react-native run-ios假設遇到這問題，首先先檢查 port 8081 有沒有被佔用了: 12$ lsof -n -i4TCP:8081$ kill &lt;pid&gt; 如果問題沒排除，試試 1sudo react-native run-ios","categories":[],"tags":[{"name":"react","slug":"react","permalink":"https://ssarcandy.tw/tags/react/"},{"name":"react native","slug":"react-native","permalink":"https://ssarcandy.tw/tags/react-native/"}],"keywords":[]},{"title":"Light Field Camera","slug":"pbrt-light-field-camera","date":"2017-01-18T11:04:29.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2017/01/18/pbrt-light-field-camera/","link":"","permalink":"https://ssarcandy.tw/2017/01/18/pbrt-light-field-camera/","excerpt":"一般傳統相機都是先對焦好之後拍攝照片，而往往會有些照片事後才發現竟然沒對好焦，甚是可惜。而光場相機(light field camera)，有別於一般傳統相機，是可以記錄相機內部的光線傳輸方向等信息的相機；光場相機就是比傻瓜相機還傻瓜的相機，允許再拍攝後根據拍攝者的需要再重新聚焦到任意的位置光場相機可以做到先拍攝，後對焦這種神奇的事情。 光場相機其實是在相機主鏡頭後面加了一層微透鏡陣列，讓原本聚焦的光再次分散到各個感光點上，如圖一：","text":"一般傳統相機都是先對焦好之後拍攝照片，而往往會有些照片事後才發現竟然沒對好焦，甚是可惜。而光場相機(light field camera)，有別於一般傳統相機，是可以記錄相機內部的光線傳輸方向等信息的相機；光場相機就是比傻瓜相機還傻瓜的相機，允許再拍攝後根據拍攝者的需要再重新聚焦到任意的位置光場相機可以做到先拍攝，後對焦這種神奇的事情。 光場相機其實是在相機主鏡頭後面加了一層微透鏡陣列，讓原本聚焦的光再次分散到各個感光點上，如圖一： 圖一：在成像平面前加一個微透鏡的陣列。微透鏡陣列的平面在這裡是 st 平面。在微透鏡陣列後面的感光元件上，每一個像素對應著 uv 平面上一個區域射到此像素對應的微透鏡上光強的和。圖源[1] 光場相機每個像素紀錄的則是只有一條光線。由於光場相機這樣的設計，所以光場相機所拍出的原始影像很特別，會是一格一格的，如圖二所示。 圖二：光場相機所拍出的原始影像是一格一格的。 這是因為微透鏡陣列對主透鏡聚集的光再成像的緣故，每一格都是對應的微透鏡的成像。事實上，可以把每個微透鏡都當作一個小小針孔相機，如圖三 (c) 所示。 另外，藉由對這些微透鏡影像的重新排列，可以生成不同視角的影像。具體來說，就是挑選每個微透鏡的同一格像素，組合出一張長寬分別等同於微透鏡在長邊以及寬邊的數量的影像。而一張光場相機原始影像能夠產生多少不同視角的影像，端看每個微透鏡後面對應到的像素有幾個。 圖三：(a)把每個微透鏡相同位置的像素取出來合成一張圖，可以得出不同視角的影像。(b)由光場影像得出的所有視角一覽。(c)每個微透鏡可以視為一針孔相機。 數位重對焦 我以之前做的 真實相機系統 為基礎，在主透鏡焦距上放置微透鏡陣列，藉此來模擬光場相機的硬體設備。光場相機原始影像紀錄了四維的光線資訊，$L(u, v, s, t)$ 這個函式代表從主透鏡的 2D 點 $(u, v)$ 射到微透鏡的 2D 點 $(s, t)$ 的光線能量，利用這個資訊，就可以進行數位重對焦。關於如何進行數位重對焦，可以看圖四。 圖四：在 s' 平面重新聚焦，即是讓所有光錐都落在 s'平面上，而對於數位重對焦而言，必須透過蒐集ｓ平面上的資訊來達成。圖源[2] 原始焦距的比例。假設要重對焦影像至 $s’$ 平面，可以由已知算出： $ s’=as+\\left(1-a\\right) u$ 不過由於光線能量函式是 $L(u, v, s, t)$ ，所以必須把 $s’$ 改寫成 $s$ 的形式： $ s=\\dfrac {1} {a}\\left(s’-\\left( 1-a\\right) u\\right) $ 所以對於一個重對焦影像的像素而言，能量可以這樣求得： $ E\\left(s’, t’\\right) = \\sum _{u} \\sum _{v} L\\left(u, v, \\dfrac {1} {a} \\left(s’ - \\left(1 - a \\right) u\\right), \\dfrac {1} {a} \\left(t’-\\left(1-a\\right) v\\right) \\right) $ 其實應該要寫成積分形式才是真實狀況，但是由於真正得到的資料是離散的(像素)，所以用加總的就可以了。 結果 我分成兩塊實作: 模擬光場相機成像，這部分是以 pbrt 為基礎再加新的 class 來實作。 利用光場相機的原始影像來做數位重對焦，這部分就是另外用 python 來做。 這樣做也使得我在驗證時可以分別驗證，讓實作上除錯較為容易。 模擬光場相機的部分，我也是用之前的場景檔為基礎，加以更改後來測試我的模擬效果。微透鏡的數目越多能使之後數位重對焦的影有更高的畫質，而微透鏡的大小則關係著能夠有多少不同的視角（亦即重對焦能力的高低）。 圖五：(a)微透鏡大小較大，但數位重對焦以後會是比較低畫質的影像。(b) 微透鏡大小較小，數位重對焦以後會是比較高畫質的影像。 圖六：數位重對焦結果。左上、右上、左下、右下分別對焦點為：遠、中、近、更近。四張皆裁切掉上方黑色區塊。 由圖六可以看出焦距的改變影響清楚的部分，雖然其實沒有十分明顯，但還是可以看到右上角的圖清楚的部分是紅龍的背部及尾部，而左下清楚的則是藍龍的背部。 另外，利用光場相機的原始影像來做數位重對焦的部分除了拿我自己產生出的光場相機影像來試驗以外，我也利用網路 [5] 直接尋找了一張光場相機的影像，並直接拿來當作我數位重對焦的測試資料，這是九個不同字母分別在不同的距離處。可以看見成功的對焦到不同的字母上。 圖七：(a)從網路 [5] 上獲得的第三方光場相機原始影像。(b)用 (a) 來測試我實作的數位重對焦，可以看見成功的對焦到不同的字母上。 雜談 其實自己模擬出來的光場影像做數位重對焦的時候效果一直不太理想，搞不懂是哪邊有問題 QQ 不過用別人的光場影像做數位重對焦很成功阿，肯定是 pbrt 那邊我寫錯了什麼… 多虧有 CMLab 的眾多強力工作站，讓我免於跑一張圖就要浪費十幾個小時的時間… 查資料一直看到 Lytro 的開箱文…. markdown + latex 還真多要注意的，markdown 的 _ 會先被轉成 &lt;em&gt; 然後像是 \\sum _{u} 的 latex 就會變成\\sum &lt;em&gt;{u}… 註:[1] Light Field Photography with a Hand-held Plenoptic Camera, R Ng, M Levoy, M Brédif, G Duval, M Horowitz, P Hanrahan[2] CS348b Project： Light Field Camera Simulation, Zahid Hossain, Adam Spilfogel Backery, Yanlin Chen[3] Fourier Slice Photography, Ren Ng, ACM Transactions on Graphics, July 2005[4] The (New) Stanford Light Field Archive[5] 光場相機原理及仿真實現[6] LYTRO Light Field Camera 原理解析","categories":[],"tags":[{"name":"pbrt","slug":"pbrt","permalink":"https://ssarcandy.tw/tags/pbrt/"},{"name":"c++","slug":"c","permalink":"https://ssarcandy.tw/tags/c/"},{"name":"rendering","slug":"rendering","permalink":"https://ssarcandy.tw/tags/rendering/"},{"name":"python","slug":"python","permalink":"https://ssarcandy.tw/tags/python/"}],"keywords":[]},{"title":"MSAuto - 玩遊戲也要自動化","slug":"MSAuto","date":"2016-12-25T13:12:48.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/12/25/MSAuto/","link":"","permalink":"https://ssarcandy.tw/2016/12/25/MSAuto/","excerpt":"最近 Facebook messanger 推出了一系列小遊戲，大部分其實都是無腦遊戲，但扯到互相比分總是會變得很激烈…. 其中有個遊戲很特別 EverWing，他是可以升級主角的射擊遊戲，也就是我可以偷練再去挑戰別人，然後分數就會很高~起初我偷練到七等左右去挑戰 David 老師，沒想到他一下就超越我了，後來又浪費我好幾個小時才超越他…。後來跑去挑戰 ball 他們，費盡千辛萬苦打到 3204 分，結果後來才發現他們都在直接發 request 作弊…。","text":"最近 Facebook messanger 推出了一系列小遊戲，大部分其實都是無腦遊戲，但扯到互相比分總是會變得很激烈…. 其中有個遊戲很特別 EverWing，他是可以升級主角的射擊遊戲，也就是我可以偷練再去挑戰別人，然後分數就會很高~起初我偷練到七等左右去挑戰 David 老師，沒想到他一下就超越我了，後來又浪費我好幾個小時才超越他…。後來跑去挑戰 ball 他們，費盡千辛萬苦打到 3204 分，結果後來才發現他們都在直接發 request 作弊…。 有圖有真相，沒作弊打 3204 分 既然他們都這樣玩，我也沒在客氣的，直接發個強一點的分數: 8 萬分。 直接發 request 獲得八萬分 後來還發現 github 上竟然有自動練等的專案 neverwing ，做得如此完整，真的是讓我開眼界了哈哈。 以上是啟發我做個自動解 MSA 任務的程式的起因。 認識我的人應該都知道我一直有在玩一個手機遊戲 Metal Slug Attack (MSA)，基本上我會玩也只是因為這是小時候玩越南大戰機台的回憶。不過有鑒於這遊戲每日任務實在是有點麻煩又耗時，所以我就想弄成自動化。 首先還是要先知道這遊戲發 request 發到哪、怎麼發、順序是甚麼、怎麼認證使用者資訊。基本上這些想知道可能要架 Proxy + Postman + 手機 root 才行了。幸好有個好東西 Charles 可以輕易的架 Proxy 讓手機的 http request 都先通過電腦再到 remote server。 知道怎麼發之後，就來開始試試吧！MSA 這遊戲有很多模式，其中一個是 TREASURE HUNT，每隔幾個小時可以領一次獎品這樣(個人覺得很沒意義的模式…)，而我也是從這模式開始下手。 TREASURE HUNT 一般而言我頂多一天進一次遊戲，那像是這種 CD 3 小時的就很浪費(原本一天可以領 8 次的)，我寫的程式邏輯挺簡單的: 每十分鐘檢查一次，冷卻好了就領獎並且重新開始搜尋。 這用 nodejs request 加上 crontab 設定一下就可以達成~ 這樣我每天都可以多好多體力 XD 接下來挑戰下個模式: COMBAT SCHOOL ，這就是每天可以打電腦三次然後會給你獎品(也是滿沒意義的模式…) COMBAT SCHOOL 在做這模式的自動化時卡滿久的，有個 POST request 的 x-www-form-urlencoded data 長這樣: 123\"cover=2&amp;deck_no=3&amp;stage_id=706&amp;training_id=1\" +\"&amp;unit_ids[]=15&amp;unit_ids[]=16&amp;unit_ids[]=17&amp;unit_ids[]=18&amp;unit_ids[]=19&amp;unit_ids[]=21&amp;unit_ids[]=84&amp;unit_ids[]=82&amp;unit_ids[]=271&amp;unit_ids[]=340\" +\"&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50&amp;unit_level[]=50\" 可以發現有一大堆 key 都是一樣的 (unit_ids[] , unit_level[] )，這用 nodejs request 似乎辦不到，所以我最後決定寫 shell script 直接用 curl 發 request ，再用 cronjob 設定每天幫刷一下關。 恩，就成功了。 再挑戰下一個模式: P.O.W RESCUE ，每天可以打 20 關電腦，會給你一些獎品(怎麼每個模式都大同小異 XD)。這是我覺得最浪費時間的模式了，因為一天要打 20 次。 P.O.W RESCUE 這邏輯稍微複雜一點，因為每次挑戰的 stage_id 都不一樣，要先 GET 下一關 stage_id ，而且又有那種 nodejs request 不能發的 request。解法兩種: 全部用 shell script 寫。 用 nodejs 寫，要發特殊 request 就另外執行 shell script。 基於我其實不太會寫 shell script，我決定採用 2 的混和寫法。利用 nodejs 判斷下一關 stage_id 再傳給 shell script 發 request。在 nodejs 中要執行 shell 可以這樣: 123456const cp = require('child_process');const job = (str, option) =&gt; &#123; return cp.execSync(str, &#123; cwd: __dirname &#125;).toString();&#125;; job('/bin/bash script.sh'); 這模式我並沒有設定 cronjob，因為我有時候想自己玩 XD。 而其他模式我現階段沒打算自動化，不然就根本都不是我在玩了… 寫這些東西其實也讓我學到一些新東西以及一些小技巧，這也算是玩 MSA 給我的收穫嗎？哈哈 其實我 code 寫得亂七八糟，但管他的可以用就好~ 最後還是附上 code: MSAuto 是說這應該算是作弊喔，抓到會被 ban 吧?不過其實被 ban 也算是一種解脫吧?","categories":[],"tags":[{"name":"trashtalk","slug":"trashtalk","permalink":"https://ssarcandy.tw/tags/trashtalk/"},{"name":"automation","slug":"automation","permalink":"https://ssarcandy.tw/tags/automation/"}],"keywords":[]},{"title":"安裝 Policyd 並設定外寄 Quota","slug":"policyd","date":"2016-12-23T16:15:40.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/12/24/policyd/","link":"","permalink":"https://ssarcandy.tw/2016/12/24/policyd/","excerpt":"最近遇到了有人使用 cmlab 的 email 亂寄垃圾信，導致很多外面 mail server 都把我們加入黑名單了…。也因此才想說要設定一個外寄上限，雖然 Postfix 本身已經有許多功能可以設定，但是就是沒辦法設定外寄的 Quota，所以就想說來試試 Policyd。 Policyd(cluebringer) 是一個可以設定一些規則給 mail server 的一個中間層(像是 middleware 那樣)。","text":"最近遇到了有人使用 cmlab 的 email 亂寄垃圾信，導致很多外面 mail server 都把我們加入黑名單了…。也因此才想說要設定一個外寄上限，雖然 Postfix 本身已經有許多功能可以設定，但是就是沒辦法設定外寄的 Quota，所以就想說來試試 Policyd。 Policyd(cluebringer) 是一個可以設定一些規則給 mail server 的一個中間層(像是 middleware 那樣)。 安裝 在 cluebringer 2.0 以前的版本不支援 IPv6，所以基本上只能從官網下載最新版，又，官網安裝說明充滿錯誤，我在弄得時候十分不開心….，所以決定自己整理安裝流程。 下載並解壓縮12$ wget http://download.policyd.org/v2.0.14/cluebringer-v2.0.14.zip$ unzip cluebringer-v2.0.14.zip 在 database/ 下，執行這段 shell script1234for i in core.tsql access_control.tsql quotas.tsql amavis.tsql checkhelo.tsql checkspf.tsql greylisting.tsqldo ./convert-tsql mysql $idone &gt; policyd.sql 這邊產出的 .sql 會有語法錯誤，用 vim 開啟並下 :%s/TYPE=innondb/ENGINE=innondb/g 指令修改全部。 初始化資料庫，建立新資料庫並匯入 policyd.sql :12$ mysql -u root -p -e 'CREATE DATABASE policyd'$ mysql -u root -p policyd &lt; policyd.sql 複製檔案到該放的地方123$ cp -r cbp /usr/local/lib/cbpolicyd-2.1/$ cp cbpadmin /usr/local/bin/$ cp cbpolicyd /usr/local/sbin/ 啟動1$ /usr/bin/perl /usr/local/sbin/cbpolicyd --config /etc/cluebringer.conf 如果啟動時遇到類似: you may need to install the Mail::SPF module 等等 error，就安裝這個: sudo aptitude install libmail-spf-perl 要查看是否有啟動成功，可以下 ps aux | grep policyd 指令。要查看 port 10031 是否有在 listen，可以下 netstat -pln | grep :10031 指令檢查。 設定 Postfix 使用 Policyd去 Postfix config 檔設定 check_policy_service : 123456789101112smtpd_sender_restrictions = ..., check_policy_service inet:127.0.0.1:10031 smtpd_recipient_restrictions = ..., check_policy_service inet:127.0.0.1:10031, permit_mynetworks, permit smtpd_end_of_data_restrictions = check_policy_service inet:127.0.0.1:10031 在 smtpd_recipient_restrictions 中，check_policy_service 需要在 permit_mynetworks 上面才有用。若要設定外寄 Quota 的話則 smtpd_sender_restrictions 也要加上 check_policy_service。 另外提醒註解不要亂放，會讓設定檔整個壞掉….可以透過 postconf 指令來列出真正 postfix 吃到的設定值 設定 Policyd Web UIpolicyd 有提供一個 web 的設定介面，讓我們比較方便設定 policyd。 複製解壓縮檔裡的 webui/ 到 web server12$ cp -r webui /var/www/$ vim /var/www/webui/include/config # 填上該填的資訊 需要把擁有者改成 www-data 12$ chown -R webui$ chgrp -R webui 就可以直接連上 web 介面: http://your.domian/webui/ 設定權限 這 web 介面預設不用登入，大家都可以隨意更改，所以必須利用其他方式加個密碼保護。 這邊是用 lighthttpd 設定密碼 123$ cd /etc/lighthttpd$ vim pwd # user:password$ vim lighthttpd.conf 詳細可以參考: Lighttpd setup a password protected directory (directories) Policyd 設定 Rate Limit到這邊就簡單了，藉由 web 介面按按按鈕就可以設定各種 Quota，詳細可參考這篇圖文教學:How To Configure Rate Limit Sending Message on PolicyD 驗證 想確定是不是有成功，可以去 mySQL &gt; policyd &gt; quota_tracking 查看是不是真的有在追蹤大家的流量。 或者也可以看 mail.log ，會有流量的 log 資訊，包含還剩多少用量等等資訊。 123$ tail /var/log/mail.log | grep cbpolicydJan 20 00:02:05 cml2 cbpolicyd[32562]: module=Quotas, mode=update, reason=quota_update,policy=6, quota=3, limit=4, track=Sender:xxx, counter=MessageCount, quota=1.00/200 (0.5%) References:[1] Policyd-Installing[2] Postfix + Centos + Policyd V2 + MySQL[3] Policyd(Cluebringer) installation[4] How To Configure Rate Limit Sending Message on PolicyD[5] Lighttpd setup a password protected directory (directories)","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://ssarcandy.tw/tags/note/"},{"name":"unix","slug":"unix","permalink":"https://ssarcandy.tw/tags/unix/"}],"keywords":[]},{"title":"pbrt - 用多點光源模擬環境光","slug":"pbrt-mediancut-environment-light","date":"2016-12-17T17:45:08.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/12/18/pbrt-mediancut-environment-light/","link":"","permalink":"https://ssarcandy.tw/2016/12/18/pbrt-mediancut-environment-light/","excerpt":"環境中總有一些背景光，像是太陽光、遠處大樓窗戶反光之類的，可以看成一整片不均勻分布的光源，有些地方亮；有些地方暗。pbrt 中是用 important sampling 來渲染環境光，不過，其實也可以把環境光轉換成一堆點光源來計算。","text":"環境中總有一些背景光，像是太陽光、遠處大樓窗戶反光之類的，可以看成一整片不均勻分布的光源，有些地方亮；有些地方暗。pbrt 中是用 important sampling 來渲染環境光，不過，其實也可以把環境光轉換成一堆點光源來計算。 不同的環境光會讓場景中物件有不同的渲染結果[1] Median Cut Alogrithm直接來看一張圖: 用 median-cut algorithm 把環境光轉成多點光源[2] 事實上這方法很簡單，就是將整張 environment light probe 切成 x 塊相同能量的區塊(x 是多少開心就好~)，整個邏輯可以分成幾步驟: 初始狀態 = 整張 env light probe 影像（陣列中只有一個區域） 對於每個區域，沿著長邊切成兩塊一樣能量的區塊 如果區塊少於 x ，則繼續做 2. 把點光源放在每個區域中的能量重心處 計算能量重心 能量重心計算其實就是 x, y 軸分別加權平均（權重為點能量）點能量計算方式可以根據 RGB channel 加權平均來計算eg. Y = 0.2125R + 0.7154G + 0.0721B 之類的加權法 計算區塊能量 直覺的想法其實就是這區塊中所有點能量和就是這區塊能量了。不過在做 Median-cut 時期時會不斷需要計算區塊的能量，用這種暴力解會使效能突破天際的差。這邊可以利用預先計算 environment light probe 的能量 Sum Area Table(簡稱 SAT)，概念很簡單:一開始先維護一個能量累積的二維陣列，每個點的值就是其左上角區塊的能量和，藉由這個陣列可以使獲得任意區塊能量的時間複雜度為 O(1)。 這張圖說明了若要獲得紅色區塊能量和，只需查表四次，計算 D-B-C+A 即可得出。 結果 渲染出來的結果其實跟原本的環境光還是有些差別，畢竟是用多點光源來模擬環境光，本來就不會一模一樣。 Median cut algorithm Important sampling(original) 不過在效能方面，用多點光源模擬所需要的運算時間大概都只有原本算法的 30% ，可以說是大幅加速了! 雜談 這次中間卡了一周跑去 SIGGRAPH ASIA，由於我懶沒帶電腦去，所以也就稍微趕了一點…(幸好這次比較簡單一點點…哈哈) 我學乖了，用 cmlab 工作站跑 pbrt 整個就是舒爽，Enter 按下去差不多就算完了~ GA 累積人次快突破 5000 瀏覽了，不過發現還真的有人在看我的文章還是覺得很特別~ 哈哈 之前 group meeting 座前面學長一直在看我的 realist-camera，害我注意力都被吸走了 XD 註:[1] 原圖來自 Physically Based Rendering, Second Edition[2] 原圖來自 A Median Cut Algorithm for Light Probe Sampling, SIGGRAPH 2006","categories":[],"tags":[{"name":"pbrt","slug":"pbrt","permalink":"https://ssarcandy.tw/tags/pbrt/"},{"name":"c++","slug":"c","permalink":"https://ssarcandy.tw/tags/c/"},{"name":"rendering","slug":"rendering","permalink":"https://ssarcandy.tw/tags/rendering/"}],"keywords":[]},{"title":"用 Facebook 聊天機器人當通知系統","slug":"cml-fb-bot","date":"2016-11-17T11:57:17.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/11/17/cml-fb-bot/","link":"","permalink":"https://ssarcandy.tw/2016/11/17/cml-fb-bot/","excerpt":"CMLab 有二十幾台 unix work stations 供大家使用(據說 CMLab 的工作站比資工系工作站還要好…)。雖然這些機器設備都很強悍，但還是有時候會出現某台機器掛掉，或是 CPU, Memory, Swap 用量過高之類的事件。若有這類事發生就必須去處理，不然一直讓機器維持在高負載很容易就死掉了。實驗室有個 網站 可以查看機器及時狀態，什麼機器有什麼問題一看就知道，超方便的。 但是不上去看就不會知道有沒有狀況，所以我就決定做個有狀況發生就通知我的 Facebook chat bot。","text":"CMLab 有二十幾台 unix work stations 供大家使用 (據說 CMLab 的工作站比資工系工作站還要好…)。 雖然這些機器設備都很強悍，但還是有時候會出現某台機器掛掉，或是 CPU, Memory, Swap 用量過高之類的事件。若有這類事發生就必須去處理，不然一直讓機器維持在高負載很容易就死掉了。實驗室有個 網站 可以查看機器及時狀態，什麼機器有什麼問題一看就知道，超方便的。 但是不上去看就不會知道有沒有狀況，所以我就決定做個有狀況發生就通知我的 Facebook chat bot。 爬網頁 最簡單的方式莫過於把網站的內容爬下來，如果有高負載或死機就通知我。我用 nodejs request 來完成這件事。 1234const request = require('request');request('https://www.cmlab.csie.ntu.edu.tw/status/', function (error, response, body) &#123; console.log(body) // Show the HTML&#125;); facebook-chat-apifacebook-chat-api 可以很容易的操作聊天室相關的行為，我利用這套件來達成通知自己。將爬下來的網頁內容，找出掛掉的機器，配合 facebook-chat-api 就可以用 fb 通知有機器掛掉了。 123456789101112131415161718192021222324// require modules let deadMachines = [];request('http://www.cmlab.csie.ntu.edu.tw/status/', function (err, res, body) &#123; const $ = cheerio.load(body); const dead = $('.dead'); for (let i = 0; i &lt; dead.length; i++) &#123; const machineId = dead.eq(i).text(); deadMachines.push(machineId); &#125; // all machines are fine~ if (!deadMachines.length) return; // login to facebook and send msg to unix manager loginFacebook(config.account, function (err, api) &#123; if (err) return console.error(err); api.sendMessage(`$&#123;deadMachines.toString()&#125; is dead.`, /* channel_id */, function (err) &#123; console.log(`$&#123;deadMachines.toString()&#125; is dead.`); &#125;); &#125;);&#125;); 透過 Facebook 聊天室告知我有機器掛掉了。 定時檢查 這隻程式並不是個持續監控的程式，只能算是個 script 而已。所以我用 crontab 設定排程定時檢查機器是不是有狀況。利用 unix 指令 crontab -e 編輯排程。 12# 每小時執行程式0 * * * * node index.js crontab 是吃 localtime，系統現在是甚麼時間可以藉由 timedatectl 查看: 12345678$ timedatectl Local time: Thu 2016-11-17 22:15:13 CST Universal time: Thu 2016-11-17 14:15:13 UTC RTC time: n/a Time zone: Asia/Taipei (CST, +0800) Network time on: yesNTP synchronized: yes RTC in local TZ: no 另外，如果設定了新的 Time Zone，則必須重啟 crontab service 才會讓他吃到正確的時間。 1$ /etc/init.d/cron restart 截圖 直到現在其實已經達成目標了，但是只講句「某某機器掛了。」似乎還是差強人意，為了防範未然，應該要把高負載的機器也告知一下，提早處理以免機器死掉。想想感覺把整個網站截圖下來傳給我不是最快嗎。恩，那就這樣弄吧！ 多虧廣大 nodejs 套件開發者，這件事可以很容易地利用 webshot 達成。 截下整個表格傳給我。 Callback to Promise爬網頁、截圖、傳訊息都是非同步的動作，寫起來就變成 Callback Hell 了。真的是醜爆了… 1234567891011// Scrap webrequest('url', function (err, res, body) &#123; /* do something with 'body' */ // Screenshot webshot(body, 'tmp.png', options, function (err) &#123; // login to facebook and send msg loginFacebook(config.account, function (err, api) &#123; // send message &#125;); &#125;);&#125;); 利用 bluebird，可以把 Callback 神奇的轉為 Promise，並且用 es6 的語法改寫，就可以大幅改善程式碼的易讀性～ 1234567891011request('url') .then(body =&gt; &#123; /* do something with 'body' */ // Screenshot return webshot(body, 'tmp.png', options); &#125;) .then(() =&gt; loginFacebook(config.account)) // login to facebook and send msg .then(api =&gt; &#123; // send message &#125;) .catch(err =&gt; console.error(err)); 完整的程式碼: https://github.com/SSARCandy/cml-status-fb-notify","categories":[],"tags":[{"name":"automation","slug":"automation","permalink":"https://ssarcandy.tw/tags/automation/"},{"name":"nodejs","slug":"nodejs","permalink":"https://ssarcandy.tw/tags/nodejs/"},{"name":"unix","slug":"unix","permalink":"https://ssarcandy.tw/tags/unix/"}],"keywords":[]},{"title":"Realistic camera in pbrt","slug":"pbrt-realistic-camera","date":"2016-11-09T05:14:41.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/11/09/pbrt-realistic-camera/","link":"","permalink":"https://ssarcandy.tw/2016/11/09/pbrt-realistic-camera/","excerpt":"Ray-tracing 中的相機(眼睛)是所有光束的起點，從相機成像平面出發的光束如果能夠經由折射、反射等等最終到達光源的那些「存活」的光束，才對最終的影像有影響的光束。這種與現實物理相反的設計(從光源發出光並追蹤那些存活到相機成像平面的光束)是為了減少計算量。","text":"Ray-tracing 中的相機 (眼睛) 是所有光束的起點，從相機成像平面出發的光束如果能夠經由折射、反射等等最終到達光源的那些「存活」的光束，才對最終的影像有影響的光束。這種與現實物理相反的設計 (從光源發出光並追蹤那些存活到相機成像平面的光束) 是為了減少計算量。ray-tracing 中，光束是從相機射出來的。[1] 實作真實相機光學系統 相機的光學系統決定了最終成像的樣貌，比如廣角、魚眼、正交投影等等樣貌， pbrt-v2 中實做了最常見的幾個，包含了 perspective camera, orthographic camera，原始程式碼在 src/camera 之下。 實際上的相機的光學系統通常都包含了多個透鏡，以此來達成比較複雜的成像(或是減少透鏡的像差)。真實相機通常都是由多片透鏡組成的光學系統。[2] 上圖是描述光學系統各個透鏡面的相關參數，從成像平面出發的 eye-ray 會在這個光學系統折射多次之後才會進入場景中，而這些光束又會跟場景的物件相交、反射等等，就如同 這篇 在做的事。 所以，要模擬真實相機的光學系統，其實就是幾個步驟： 在成像平面上與第一個透鏡面上各取一點，相連產生 eye-ray 找出 eye-ray 與第一個透鏡面的交點，沒交點就結束 找出折射後的新 eye-ray 重覆 2, 3 直到 eye-ray 離開光學系統進入場景為止 以 pseudo-code 表示，大概可以寫成這樣： 123456789101112131415filmP = random point on filmlensP = random point on first lensray.o = filmPray.d = Vector(lensP - originP) for l in lens: # from rear to front intersectionP = l.intersect(ray) if not intersectionP: return 0 newDirection = l.refractRay(ray) if not newDirection: return 0 ray.d = newDirection 其實也可以借助一些除錯工具來視覺化光束的折射行為，這邊我使用 vdb 來畫出整個光學系統並且追蹤光束的折射行為。(關於如何利用 vdb 除錯，可以參考 這篇。)pbrt 模擬從成像平面中點發出光束，經過多次折射直至離開相機鏡頭。 除此之外，也需要計算每條 ray 的權重，根據論文 [2] 所說是如下公式： $E = A\\frac{cos^4\\theta}{Z^2}$ $A$: 出射瞳面積$Z$: 最後透鏡與成像平面的距離$\\theta$: 光束與成像平面法向量夾角 結果 我嘗試渲染大張一點的圖並且讓每個像素的採樣夠多次，希望能夠讓結果圖漂亮一點。代價就是一張圖要跑好幾個小時…… dobule-gauss 50mm with 512 samples per pixel(1024*1024) wide 22mm with 512 samples per pixel(1024*1024) telephoto 250mm with 512 samples per pixel(1024*1024) fisheye 10mm with 512 samples per pixel(1024*1024) 加速 每個透鏡面基本上是以部份的球面來模擬，要求交點很容易，因為 src/shape/shpere.cpp 已經實做求交點了，可以直接創一個 Sphere object ，然後再 s.Intersect(r, &amp;thit, &amp;rayEpsilon, &amp;dg) 來取得交點。 這樣寫簡單易懂，三兩下解決求交點這件事，但其實效能並不好，因為只為了求一個交點卻建構了一個完整的 shpere shape ，稍微有點浪費…… 改善方式可以藉由複製貼上 Shpere::Intersect() 並加以改寫，就可以省去這樣的 overhead實際上效能大約差 2 倍。 各種坑 RasterToCamera在 GenerateRay() 中，sample.imageX sample.imageY 是在 Raster space 上，需轉至 Camera space，Raster/Camera space 之間關係如圖(省略 z 軸)，可以看出來轉換方式大概就是：上下翻轉、平移、縮小。Raster/Camera space 之間關係。 Ray minT, maxT在 GenerateRay() 中產生的 ray 記得參數要給好給滿，之前因為沒給值到 min/maxT 導致結果有坑坑巴巴的破圖… Total reflection我使用 Snell’s law 計算折射後的新方向，在公式中，若發生全反射時會讓其中一項產生虛數，程式就整個爆炸了。所以記得要注意別把負數開根號了。 註: [1] 圖片取自維基百科 Ray-tracing) [2] A Realistic Camera Model for Computer Graphics, SIGGRAPH 1995","categories":[],"tags":[{"name":"pbrt","slug":"pbrt","permalink":"https://ssarcandy.tw/tags/pbrt/"},{"name":"c++","slug":"c","permalink":"https://ssarcandy.tw/tags/c/"},{"name":"rendering","slug":"rendering","permalink":"https://ssarcandy.tw/tags/rendering/"}],"keywords":[]},{"title":"vdb - Debugging visual programs","slug":"debug-using-vdb","date":"2016-10-13T12:34:53.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/10/13/debug-using-vdb/","link":"","permalink":"https://ssarcandy.tw/2016/10/13/debug-using-vdb/","excerpt":"有時候在寫 openGL 或者是類似 pbrt 這樣有牽涉到三維空間的程式的時候總是很難除錯…雖然可以設斷點看看變數內容有沒有問題，但說實在的其實這樣看有時候根本看不出所以然，這樣還是難以除錯。 vdb 是一個解決這樣問題的工具，它提供了很多常見的畫線、畫點等等函式，最重要的是他的易用性，可以在幾乎不更動程式碼的狀態下就完成偵錯。","text":"有時候在寫 openGL 或者是類似 pbrt 這樣有牽涉到三維空間的程式的時候總是很難除錯…雖然可以設斷點看看變數內容有沒有問題，但說實在的其實這樣看有時候根本看不出所以然，這樣還是難以除錯。 vdb 是一個解決這樣問題的工具，它提供了很多常見的畫線、畫點等等函式，最重要的是他的易用性，可以在幾乎不更動程式碼的狀態下就完成偵錯。 Usage其實在 vdb README 已經說的滿清楚的了，這邊在整理一下: 下載 vdb-win.zip 或 vdb-osx.tar.gz 把 vdb.h include 進你要偵錯的程式 執行 vdb.exe 或 ./vdb 在要偵錯的程式中，可以在任何地方插入 vdb_line() 等他所提供的函式 Example以 pbrt 為例，由於結果都是一張渲染完成的影像，說實在的這真的很難 debug….那利用 vdb 這工具能有甚麼好處呢？ 藉由他，可以很容易地畫出像是物體的樣子以及他的 Bounding Box，如圖：heightfield object and its bounding box 或者是當你在算 Vertex normal 時，不知道到底算的對不對，也可以直接畫出來：Showing Normals on vertices 我個人覺得 vdb 對我最大的幫助是 object space 以及 world space 之間的關係了，坐標系一個沒弄好就會讓渲染的結果差異甚大，完全摸不著頭緒到底發生什麼事情….. 藉由 vdb 實際畫出各個 object 時候，很容易就發現 object/world space 之間的 bugBounding box 沒有正確的轉換到 object space，導致跑到怪怪的地方 Some tips其實上面說的很簡單，但事實上我剛開始嘗試使用 vdb 時遇到了超多的問題，這邊就來記錄一下： Header files order#include &quot;vdb.h&quot; 要擺在哪裡？一般來說當然越上面越好，但還是有例外的： heightfield.cpp12345#include \"stdafx.h\"#include \"vdb.h\"#include \"shapes/heightfieldImproved.h\"#include \"shapes/trianglemesh.h\"#include \"paramset.h\" 以上面的例子來說，#include &quot;vdb.h&quot;必須放在 #include &quot;stdafx.h&quot;後面。stdafx.h是來做 precompiled headers 用的，所以置於他之前的 include 都會被忽略，就會造成找不到 vdb_line() 之類的錯誤。 Use ONE threadvdb 不支援多執行緒，如果在偵錯的程式是多執行緒的話，有可能會導致畫在 vdb 上的東西不正確 (漏畫)。 解決方法就是在偵錯時使用單一執行緒。 Using winsock instead of winsock2這問題應該是只在 Windows 會發生，並且在要偵錯的程式中使用到 windows.h。vdb 中用到了 winsock2.h，這是跟 socket 有關的東西，然而 windows.h 中也有 include 一個叫 winsock.h 的東西。winsock.h, winsock2.h 有很多函式都各自有宣告，而同時引用兩者會造成 redefinition 錯誤。 解決方法是把 vdb.h 中，winsock2.h改成 winsock.h。 詳細可查看 stackoverflow 這篇","categories":[],"tags":[{"name":"pbrt","slug":"pbrt","permalink":"https://ssarcandy.tw/tags/pbrt/"},{"name":"c++","slug":"c","permalink":"https://ssarcandy.tw/tags/c/"}],"keywords":[]},{"title":"改善 pbrt 中的 heightfield shape","slug":"pbrt-heightfield","date":"2016-10-10T13:14:41.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/10/10/pbrt-heightfield/","link":"","permalink":"https://ssarcandy.tw/2016/10/10/pbrt-heightfield/","excerpt":"pbrt 是一個基於物理的 ray-tracing libarary，他可以拿來產生接近現實的真實場景，據說 IKEA 的型錄都是用類似方法產生的，而不是真的把產品擺出來拍照。 哈哈","text":"pbrt 是一個基於物理的 ray-tracing libarary，他可以拿來產生接近現實的真實場景，據說 IKEA 的型錄都是用類似方法產生的，而不是真的把產品擺出來拍照。 哈哈據說 IKEA 型錄的圖都是渲染出來的[1] 關於 pbrt 與 ray-tracingRay-tracing 說穿了就是在模擬自然界光線的運作，我們之所以看的到東西，其實就是因為光線打到物體並反射到我們眼睛，這也是為甚麼在無光的地方會伸手不見五指 (因為沒有任何光打到手指並反射到眼中)。 至於電腦要怎麼模擬這件事，大致來說是光線從光源出發，途中遇到障礙物就要算交點，有交點就要根據材質特性反射，反射之後就是一條新的光線，就繼續做交點測試直到進到眼睛中(或直到能量遞減完畢)。可以看出，ray-tracing 最重要的大概就是與物件算交點了，因為 ray 會一直做交點測試，所以與物件的交點測試必須要夠快才行，不然就會算到天荒地老…. pbrt 除了最基本的 triangleMesh 以外，還實作很多其他一些常見的 shape(球體、圓柱體、圓形、heightfield…)，這其實是拿來給 api 使用的，一般人可以寫 pbrt 專用的描述檔來描述一個場景中的物體、光源等等，再藉由 pbrt 的程式來渲染出整張影像。 pbrt 中的各種 shape，有些是會先轉成 triangleMesh(對三角形求交點應該是圖學中最基礎的了，如果原本物件太複雜通常就會先把它拆成三角形組合再來算)；而有些是有實作對 shape 交點測試的。由於把物件轉成 triangleMesh 其實就硬是多一個步驟了啊，如果可以與 shape 直接求交點，那速度上當然會大躍進~ 實作 heightfield 交點測試Heightfield 其實就是平面但是有高低差，也就是說，對每個 $(x, y)$ 而言只會有一個 $z$ 值。算是個滿單純的 shape。Heightfield 也是原本就有實作的一種 shape，是直接用 Refine() 來把形狀轉為 triangleMesh 再做交點測試的。 如果能夠跳過三角化而直接與 heightfield 做交點測試，可能可以比較快喔？參考一下別的 shape，包含球體、圓柱體等實作的交點測試的方法都是在幾何意義上直接求交點，也就是算數學求解~ 哈哈 但 heightfield 似乎是沒辦法從幾何意義上直接解了，需要用更暴力的方法~ 這邊我是使用 DDA(digital differential analyzer) 來做交點測試，這東西其實原本是拿來畫線的演算法，因為實際上的線是連續的，但是呈現在電腦上卻必須以 pixel 為單位呈現。而這邊與 heightfield 的交點測試就是將 DDA 擴展至三維空間中(多了 Z 軸)。2D-DDA 邏輯。[2] 可以看到其實可以在一開始就算出 x, y 要走多少會到下一個 pixel，這些都是定值，也讓遍歷整個 Pixel-Grid 變得很容易，而 3D-DDA 就只是再加入 z 軸的資訊，並且每一個 pixel 變成 voxel。3D-DDA 這樣的方式其實在 pbrt 裡面已有實作，是來作為加速結構用途，但是由於 heightfield 本身特性(對每個 $(x, y)$ 而言只會有一個 $z$ 值)，我們可以讓 Voxel 的高度等於 heightfield 的高度，如此一來就可以讓 3D 結構的 heightfield 套用 2D-DDA 了！耶~~~ 建好 DDA 需要的資訊後，接下來就是要實作 Ray 交點測試了，在遍歷 Voxel 的過程中，需要針對這個 Voxel 做交點測試，如果有交點就結束了；沒有就到下個 Voxel。而關於每個 Voxel 的交點測試其實也是滿單純的，在設計 DDA 的結構時，除了讓 Voxel 高等於 heightfield 高，可以變成 2D-DDA 以外，讓 Voxel 的寬等於一個單位的 x 及 y 也是有很大的好處的，如下圖:從正上方看下來的 heightfield 樣子，數值為對應 z 值。讓 Voxel 寬度等於一格寬有好處。 依據這樣的設計，每次在做 Voxel 交點測試時，可以知道這 Voxel 中就是包含兩個三角形；也就是說分別對這兩個三角形做交點測試就好了~~ 根據這樣的算法，就可以得出與原本直接三角化的做法一模一樣的結果:用直接求交點的方式取代原本先做三角化的方法。 平滑化 看看上圖的結果，看得出都是一面一面的三角形面，這是因為同一個面上所有點都是一樣的法向量，所以反射角度也都一樣，自然就成這副德性。如果要做平滑化的話就必須內插三角形內部的點的法向量，使得三角面反射光會看起來滑順一點。三角化後每個點 M 都有六個鄰居。 這邊我是直接平均法向量來達成這樣的效果，由於三角化之後每個點會有六個鄰居；點 M 的鄰居有 TL、T、R、BR、B、L 六點，點 M 的法向量可以藉由任意兩向量外積得出。 那我就平均一下六個法向量來當作真正的法向量，以 M 為原點，可算出平均法向量為:$\\underset{Normalize(}{}\\underset{TL}{\\rightarrow} \\underset{\\times}{} \\underset{L}{\\rightarrow} \\underset{+}{} \\underset{L}{\\rightarrow} \\underset{\\times}{} \\underset{B}{\\rightarrow} \\underset{+}{} \\underset{B}{\\rightarrow} \\underset{\\times}{} \\underset{BR}{\\rightarrow} \\underset{+}{} \\underset{BR}{\\rightarrow} \\underset{\\times}{} \\underset{R}{\\rightarrow} \\underset{+}{} \\underset{R}{\\rightarrow} \\underset{\\times}{} \\underset{T}{\\rightarrow} \\underset{+}{} \\underset{T}{\\rightarrow} \\underset{\\times}{} \\underset{TL}{\\rightarrow} \\underset{)}{}$ 這樣子改進後，就可以讓結果變這樣:平滑化的結果 浮點數精度問題 (10/22 更新) 做完平滑化之後，感覺海好像怪怪的歐….一開始其實我還沒察覺，過這麼久才發現這問題… 很顯然只有海有這樣的問題，八成是因為海的 $z$ 值差距太小，計算法向量時的誤差。用這樣的思維去追查程式後，發現我原本在算六個法向量總和後有做 Normalize(sumOfNormals)，這步驟造成 $z$ 值起伏太小的海的計算誤差….把 Normalize() 拔掉之後就正常了～ 修正浮點數精度問題後的結果 加速 很可惜的是我做完以後，速度沒有想像中的快速，反而比原本的還慢了兩倍以上…. 嗚嗚嗚….稍微看看別的 shape 的交點測試，其實有很多時候會先跟 Bbox(Bounding Box) 做測試，因為與 Bbox 交點是容易很多的，如果與 Bbox 無交點就也不用繼續做下去了。在 Voxel 交點測試中，也應當先與整個 Voxel 做測試，確定有交點再去試裡面的兩個三角形，這樣就可以省下很大量的做白工。 但這樣做完還是不夠好，所以我利用 CPU profiling 來測試我的程式的瓶頸到底在哪裡….利用這樣的檢測，我陸續做了幾次優化: 原因及改善方法 Intersect() 與未最佳化時比較 未最佳化。 90,274 100.0% 發現 ObjectBound() 很慢，改在 Heightfield construction 時就先存 minZ, maxZ。 82,731 91.6% 發現在算 Voxel BBox 使用的 Bbox(Union(Bbox, Bbox)) 超爆慢，改用 Bbox(Point, Point)。 53,408 59.1% 發現有不必要的坐標系轉換，由於在 Voxel 交點測試中會先測與 Voxel Bbox 交點，所以最好直接給他已轉好的 Ray(Object Space)。 46,922 51.9% 由於 Bbox(Point, Point) 建構時都要重新判斷 min max，改用先建構空的 Bbox 再直接給值 (pmin, pmax) 省去建構時間。 36,768 40.7% 把用不到的 Bbox 給 Voxel 交點測試中再利用，節省 Construction Time(避免重新 relocate 記憶體位置以及建構空 Bbox 的時間)。 32,742 36.2% Intersect() 欄的數字是指 CPU 採樣時落在這函式的總樣本數，越多表示執行時間越長 測試的是 landsea-2.pbrt，並且使用 –ncores 1 以減少多執行緒的誤差 經過幾次最佳化後，成功壓低執行時間(單位為秒)，效能比較如下:效能比較。[3] 雜談 說真的這大概是我做過數一數二難的作業了，而且竟然只是作業一….其實寫的過程也不是我自己想到的，老師也有給提示，甚至網路上其實根本有答案….(不見得是最佳解就是了)為了這作業我甚至還上 Stack overflow 問了人生第一個問題 哈哈 (雖然問題跟演算法沒關係) 只能說不愧是 Stanford 的題目囉？ 註: [1] 可以看 這篇 介紹 IKEA 渲染型錄 [2] 原圖來自 Physically Based Rendering, Second Edition [3] 執行時間用 bash 內建 time 指令來量測","categories":[],"tags":[{"name":"pbrt","slug":"pbrt","permalink":"https://ssarcandy.tw/tags/pbrt/"},{"name":"c++","slug":"c","permalink":"https://ssarcandy.tw/tags/c/"},{"name":"rendering","slug":"rendering","permalink":"https://ssarcandy.tw/tags/rendering/"}],"keywords":[]},{"title":"一些 Python 筆記","slug":"python-note","date":"2016-09-09T16:28:57.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/09/10/python-note/","link":"","permalink":"https://ssarcandy.tw/2016/09/10/python-note/","excerpt":"最近的專案需要用到 OpenCV，官方有提供 C++ 以及 Python 的版本。我以前都用 C++，這次想說來換換口味使用 Python 好了，如果用的順手以後就都這樣搭配著用(Python + OpenCV)。說是這樣說，但其實我對 Python 根本一竅不通，從來沒在比較大的專案中使用過，所以新手如我自然就遇到很多坑(?)","text":"最近的專案需要用到 OpenCV，官方有提供 C++ 以及 Python 的版本。我以前都用 C++，這次想說來換換口味使用 Python 好了，如果用的順手以後就都這樣搭配著用 (Python + OpenCV)。 說是這樣說，但其實我對 Python 根本一竅不通，從來沒在比較大的專案中使用過，所以新手如我自然就遇到很多坑(?) 我這次專案是 Python 2.7 + OpenCV 3.1。安裝 OpenCV 一直都是很麻煩的事情，C++ 的免不了要自己 build，詳細的方法在我之前寫的 另一篇 有教學；而 Python 安裝 OpenCV 稍微簡單一點，把 cv2.pyd 放到 C:\\Python27\\Lib\\site-packages 就可以了 [1]。在 Mac/Linux 上更簡單，可以使用 conda [2] 來幫你安裝。 好，接下來就是用到現在所做的一些筆記～ Coding-stylePython 的 Coding-style 基本上就是參考 PEP8，簡結一下重點: 縮排用空格 一行不要超過 80 個字元，超過就換行。 除了 ClassName 以外，一律用 snake_case 為命名規則。 文件首行要加上編碼，一般 utf-8 就是加上這行 # -*- coding: utf-8 -*- DivisionPython2 的除法很特別，竟然只除到整數，意思就是 5 / 2 = 2，不過這其實就跟 C++ 一樣嘛，強制轉型一下就好: 123print(5 / 2) # 會無條件捨去小數點，印出 2print(5 / 2.0) # 2.5print(5 / float(2)) # 2.5 不過這樣好麻煩，有沒有一勞永逸的方法？有！就是用神奇的 __future__ 12# 在文件開頭處加上這行from __future__ import division future 是 Python2 很特別的東西，感覺上就是抓 Python3 的功能來用，而這邊 import division 就是使除法的行為與 Python3 一致，詳細運作原理可以參考 stackoverflow 上的說法: The internal difference is that without that import, / is mapped to the __div__() method, while with it, __truediv__() is used. Class網路上有許多宣告 Class 的教學，不過好像大部分的都不對或過時了。在 Python2 中，Class 宣告方式如下： class.py123456789101112131415class Foo(object): def __init__(self): self.bar1 = 'hello' self.bar2 = 'world' def hello_world(self): print(self.bar1 + '' + self.bar2) def __private_func(self): print('I am private function') foo = Foo() # new 一個新的 Foofoo.hello_world() # 不用帶任何參數foo.__private_func() # 無法呼叫，會噴 Error: AttributeError:'Foo'object has no attribute'__private_func' 第一行的 object 是必須的。 __init__ 這個 function 也是必須的，這是 Class Constructor。 每個 function 的第一個參數必須放 self，這與 C++ Class 中的 this 相似，基本上就是拿來存取 自己 用的。 例如 hello_world() 中就有存取 bar1 跟 bar2，而在呼叫時 self 會被跳過。 如果要寫 private method [3]，就在 function name 前加上雙底線 __，如同上面的第 9 行處。 Path檔案路徑也是一個滿麻煩的事情，假設要讀一個檔案，一開始可能會這樣寫： 1cv2.imread('../data/foo.jpg') # cv2.imread 是 opencv 的讀圖函式 這樣當然可以讀的到，但當你換了一個工作環境，像是 Windows，這樣寫就炸了～(因為 Window 路徑是用反斜線 \\)Python 提供了個好工具 os.path.join()，簡單來說就是幫忙處理斜線。所以上面那個例子可以改寫成這樣： 12import oscv2.imread(os.path.join('..', 'data', 'foo.jpg')) 這樣的寫法就可以順利地在各平台運作～！ Function name and Variable name每個程式語言都有保留字，像是 for, while, if 之類的都是常見的保留字，而 Python 也不例外，你可以在 這邊 看到全部的保留字。而通常 function name 也跟保留字一樣不能當作變數名稱 [4]。特別的是 Python 允許變數名稱與 function 名稱一樣，像是： 123sum = sum([1,2,3,4,5]) # sum() is built-in function for pythonprint(sum) # 15print(sum([1,2,3,4,5])) # 15 上面的例子可以看到，Python 能夠清楚的分辨這個 sum 是指變數還是內建函式。javascript 就不行： 123btoa = btoa('hello') // btoa() is built-in function for javascriptconsole.log(btoa) // aGVsbG8=console.log(btoa('hello')) // Uncaught TypeError: btoa is not a function 可以發現在第三行就噴錯了，因為 btoa 在第一行已經被蓋掉了，後面要用 btoa() 就會以為你是指那個變數，而變數當然不是 function 囉。 The Zen of PythonPython 作者 Tim Peters 把一首詩藏在 import this 中， Beautiful is better than ugly.Explicit is better than implicit.Simple is better than complex.Complex is better than complicated.Flat is better than nested.Sparse is better than dense.Readability counts.Special cases aren’t special enough to break the rules.Although practicality beats purity.Errors should never pass silently.Unless explicitly silenced.In the face of ambiguity, refuse the temptation to guess.There should be one– and preferably only one –obvious way to do it.Although that way may not be obvious at first unless you’re Dutch.Now is better than never.Although never is often better than right now.If the implementation is hard to explain, it’s a bad idea.If the implementation is easy to explain, it may be a good idea.Namespaces are one honking great idea – let’s do more of those! 寫 Python 就是要追求乾淨、易讀、簡單，這也是我這幾周使用 Python 所感覺到的。再引用 David 老師所言， 寫 Python 就像是在寫 pseudo-code 一樣爽！ 註:[1] cv.pyd 可以在 build 好的 opencv 資料夾中找到。[2] OpenCV 不能用 pip 安裝，而 conda 是類似 pip 的 Python 套件管理軟體。[3] Python 是沒有 private function 的，只是在 runtime 藉由更改 function name 來達到這樣的效果，詳細可以參考 這篇 。[4] 函式名子 不一定 不能當作變數名稱，在 C/C++ 中會有 Compile-time Error，在 javascript 中是可以的，但是會覆蓋其內容。","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://ssarcandy.tw/tags/note/"},{"name":"opencv","slug":"opencv","permalink":"https://ssarcandy.tw/tags/opencv/"},{"name":"python","slug":"python","permalink":"https://ssarcandy.tw/tags/python/"}],"keywords":[]},{"title":"談談 vim plugin-manager","slug":"vim-plugin-manager","date":"2016-08-17T03:02:10.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/08/17/vim-plugin-manager/","link":"","permalink":"https://ssarcandy.tw/2016/08/17/vim-plugin-manager/","excerpt":"我用過了幾乎所有有名的 vim plugin-manager，包含 Pathogen, Vundle 以及比較新的 vim-plug。而以時間序來說也是 Pathogen -&gt; Vundle -&gt; vim-plug 先來談談用過這三個分別的感想好了：","text":"我用過了幾乎所有有名的 vim plugin-manager，包含 Pathogen, Vundle 以及比較新的 vim-plug。而以時間序來說也是 Pathogen -&gt; Vundle -&gt; vim-plug 先來談談用過這三個分別的感想好了： Pathogen簡單好用，與其說是 plugin-manager，個人覺得比較像是個純粹的 run-time loader，沒有什麼其他的功能。但已十分好用，要新增什麼 plugin，只需把 plugin 的資料夾放在 bundle/ 底下就完工了！刪除也是，直接砍掉 bundle/ 底下對應資料夾就 OK Vundle目前應該是這三者中 github stars 最多的。plugin 安裝方式是在 .vimrc 中寫你要的 plugin name 1Plugin 'tpope/vim-fugitive' 然後在 vim 中打 :PluginInstall 就會幫你安裝。 這樣的好處是你裝過什麼一目了然，而且到新環境要重新設置的時候也很方便，直接 :PluginInstall 就完成了。(如果用 Pathogen 就必須自己把要用的 plugins clone 下來。) vim-plug我目前在使用的 plugin-manager ，給我的感覺就是 Vundle 的加強版。新增 plugin 的方式跟 Vundle 很像(只是關鍵字不同)，都是在 .vimrc 中寫你要的 plugin name 1Plug 'tpope/vim-fugitive' 安裝也是跟 Vundle 差不多，關鍵字不一樣而已 (:PlugInstall) 比較厲害的是 vim-plug 可以 on-demand loading！像是 vim-go(強大的 Golang Dev-plugin)，這種只有在寫 golang 時候才要的 plugin，就應該只在副檔名是 .go 的時候載入就好；NERDTree 也是，有時候只是打開一個檔案要編輯而已，用不著這個套件，只有當真的觸發開啟 NERDTree 的時候再載入就好。這些 vim-plug 都可以設定(設定方式詳見 readme)，大幅提升 vim 開啟速度～ 效能 我從 Pathogen 換到 Vundle 是為了可以很容易的在新環境設定好 vim，而從 Vundle 換到 vim-plug 則是為了他的 on-demand loading。 所以說到底效能差多少？其實我並不是個重度 plugins 使用者，有在用的 plugins 大概 20 個吧。所以從 Vundle 換到 vim-plug 說實在並沒有顯著效能差異。不過還是可以看看別人的實驗不同 plugin-manager 的開啟速度(plug = vim-plug)。圖片出自 vim-plugins-and-startup-time 不難發現，有 on-demand loading 的 plugin-manager 開啟速度會快不少，以圖中為例大概都可以快上個 30% ！如果有興趣，也可以自己試試 vim 的開啟速度，可以用以下的方法測量。 1$ vim --startuptime vim.log 詳細開啟資訊都會寫入 vim.log References:[1] vim-plugins-and-startup-time[2] vim.tw","categories":[],"tags":[{"name":"vim","slug":"vim","permalink":"https://ssarcandy.tw/tags/vim/"}],"keywords":[]},{"title":"用 Travis CI 自動部屬 hexo 到 GitHub","slug":"hexo-auto-deploy","date":"2016-07-28T16:51:43.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/07/29/hexo-auto-deploy/","link":"","permalink":"https://ssarcandy.tw/2016/07/29/hexo-auto-deploy/","excerpt":"其實 hexo 作者 TC 已經有發過一篇文章在講這個主題了，也講得很清楚了，基本上矇著眼睛照做就行了。而這篇主要是再補充幾個細節。","text":"其實 hexo 作者 TC 已經有發過 一篇文章 在講這個主題了，也講得很清楚了，基本上 矇著眼睛 照做就行了。而這篇主要是再補充幾個細節。 SSH KEY 矇著眼照做 那篇，到這行: 1$ travis encrypt-file ssh_key --add 這邊會幫你上傳 ssh_key 到 Travis 上，--add這個 flag 可以幫你插入解密指令到 .travis.yml 的before_install。 不過這 flag 真的很機車，會把你的 .travis.yml 排版全搞亂，順便把註解刪光光！ 建議不要加 --add 自己手動插入解密指令，排版就不會亂掉。 而且用 Windows 的人會在解密文件時莫名失敗，所以只能用 Mac 或 Unix 環境做這件事(File decryption fails on Windows)，超雷… 另外，如果因某種天災人禍導致忘記或沒辦法用指令插入解密指令，還是可以上 Travis 上的設定中看到環境變數名稱。 repository> more options 可以設定、看到 Travis 的環境變數 USE SSH Travis 是用 GitHub 的 Deploy key 來存取 repository 的，關於如何產生以及設定 Deploy key 都照著 TC 那篇文章 做就可以了。 如果不幸在 hexo deploy 時遇到錯誤如下: 12remote: Invalid username or password.fatal: Authentication failed for &quot;....&quot; 那可以檢查一下 hexo 的 _config.yml deploy 的部分，要用 ssh 的形式設定 repository _config.yml1234deploy: type: git repo: git@github.com:SSARCandy/ssarcandy.github.io.git branch: master SETTING UP .travis.yml我這個網站結構如下: [develop] -&gt; default branch，我在這條 branch 新增文章、修改樣式等等[master] -&gt; 放 static-files，也就是 hexo generate 出來的東東 讓 Travis 自動部屬時，Clone 的是 develop branch， 經過 hexo generate 後推到 master branch 上，為了避免 forced-update，在.travis.yml 中需要再設定一下。 附上我的 .travis.yml，基本上跟 TC 那篇 87% 像啦…title: .travis.yml123456789101112131415161718192021222324252627282930313233language: node_jsnode_js: - \"4\" before_install: # Decrypt the private key - openssl aes-256-cbc -K $encrypted_d7634ff77415_key -iv $encrypted_d7634ff77415_iv -in .travis/ssh_key.enc -out ~/.ssh/id_rsa -d # Set the permission of the key - chmod 600 ~/.ssh/id_rsa # Start SSH agent - eval $(ssh-agent) # Add the private key to the system - ssh-add ~/.ssh/id_rsa # Copy SSH config - cp .travis/ssh_config ~/.ssh/config # Set Git config - git config --global user.name \"ssarcandy\" - git config --global user.email ssarcandy@gmail.com # Install Hexo - npm install hexo -g # Clone the repository - git clone https://github.com/SSARCandy/ssarcandy.github.io .deploy_git # My static-files store on master branch - cd .deploy_git &amp;&amp; git checkout master - cd .. script: - hexo generate - hexo deploy branches: only: - develop 比較需要解說的是這段1234# Clone the repository- git clone https://github.com/SSARCandy/ssarcandy.github.io .deploy_git- cd .deploy_git &amp;&amp; git checkout master- cd .. .deploy_git是 hexo 會產生的資料夾，用於紀錄 git history，不過由於每次 clone 都是全新的，所以每次 .deploy_git 也都會是新的，這會導致每次更新都會是 forced-update。所以，複製一份 repo (at master branch)，並改名叫 .deploy_git 就是為了讓新產生出的靜態檔案可以有之前的 git history，就可以避免 forced-update。","categories":[],"tags":[{"name":"automation","slug":"automation","permalink":"https://ssarcandy.tw/tags/automation/"},{"name":"hexo","slug":"hexo","permalink":"https://ssarcandy.tw/tags/hexo/"}],"keywords":[]},{"title":"自動分享每日天文圖 (APOD) 到 Dcard","slug":"bot-battle","date":"2016-07-26T16:16:45.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/07/27/bot-battle/","link":"","permalink":"https://ssarcandy.tw/2016/07/27/bot-battle/","excerpt":"原本其實只是要做個 Slack bot，因為我懶得每天都上 APOD 官網看…乾脆做個 bot 每天都會在中午 12:30 發今日的圖跟說明到 Slack channel 裡～","text":"原本其實只是要做個 Slack bot，因為我懶得每天都上 APOD 官網看…乾脆做個 bot 每天都會在中午 12:30 發今日的圖跟說明到 Slack channel 裡～自動發文到 slack channel 裡，然後還隨機搭配內容農場風格的一句話。 不過除了我自己以外好像都沒什麼人捧場，幾乎都被無視 QQDavid 老師 還表示很煩要我關掉 (明明一天才 Po 一次啊啊啊 ಠ_ಠ 所以我只好忍痛取消這個 Slack bot，改成直接用 Direct message 傳給 David 老師 XD 結果 David 老師 也做了個每半小時就發名言佳句給我的 bot， 害我只好也把我的 bot 改成每十分鐘隨機發天文圖給他，看誰比較耐得住煩～每半小時發給我一句名言佳句，真是世界煩。 當然這種互相毀滅的 bot 大戰持續沒多久就在雙方讓步之下都停止了….. — 以上都是前言 — 即使 Slack 上都沒人要鳥我，我還是秉持著推廣基礎天文教育的偉大理念，認為優質的每日天文圖的不應該被埋沒，要讓這樣優質的內容給更多人接觸到！最後突然想到：「不然乾脆發在 Dcard 廢版好了，那邊最多人在看了而且不受版規限制」可是懶人如我是不可能每天上去 Po 文的，所以又寫了個 bot 每天中午戳 Dcard API，發優質天文圖到廢版(廢文？發廢文到廢版 結果意外反應還不錯？還有人想要我整理系列文，不愧是廢版版友，就是有眼光！大家都很捧場，覺得溫馨 ╰(〞︶〝) ╯ 不知道要過多久才會有人會發現這都是 bot 在發文 XDD –最後自己推銷一下，由於 APOD 只有 NASA 有提供官方 API，除了英文以外其他語言的子站 (像是中文版) 都沒辦法簡單的取得內容，所以我寫了一個 npm 套件，專門處理取得指定日期、指定語言的 APOD 內容。Github: https://github.com/SSARCandy/node-apodDemo: http://ssarcandy.tw/node-apod/demo.html","categories":[],"tags":[{"name":"trashtalk","slug":"trashtalk","permalink":"https://ssarcandy.tw/tags/trashtalk/"},{"name":"automation","slug":"automation","permalink":"https://ssarcandy.tw/tags/automation/"}],"keywords":[]},{"title":"Setting up OpenCV using Cmake GUI","slug":"Setting-up-OpenCV-using-Cmake-GUI","date":"2016-07-22T16:46:45.000Z","updated":"2017-02-13T16:09:25.881Z","comments":true,"path":"2016/07/23/Setting-up-OpenCV-using-Cmake-GUI/","link":"","permalink":"https://ssarcandy.tw/2016/07/23/Setting-up-OpenCV-using-Cmake-GUI/","excerpt":"Build OpenCV Download OpenCV and Cmake Build opencv with cmake Press configure, choose visual studio 2015, finish Then press generate","text":"Build OpenCV Download OpenCV and Cmake Build opencv with cmake Cmake configuration Press configure, choose visual studio 2015, finish Then press generate Open OpenCV.sln under build/ Build it using Debug, Release Right click> build right click &gt; build switch to Release mode and build again [Windows] Setting up environment variable add &lt;opencv&gt;/bin into PATHAdd new environment variable add new env named OpenCV_DIR, value as &lt;opencv&gt;/build it may need logout to apply setting, you can check it by echo %PATH%, echo %OpenCV_DIR% Build with EXTRA MODULES In step 2. Build opencv with cmake, press configure Set up OPENCV_EXTRA_MODULES_PATH to proper path(&lt;opencv_contrib&gt;/modules) Set OPENCV_EXTRA_MODULES_PATH as opencv_contrib/modules Press configure again, then generate To see more details instructions, see opencv_contrib README Travis.yml exampletitle: travis.yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061language: - cpp sudo: required compiler: - gcc # building opencv is time consuming, caching it is bettercache: apt: true ccache: true directories: - opencv-3.1.0 - opencv_contrib-3.1.0 install: # OpenCV dependencies - Details available at: http://docs.opencv.org/trunk/doc/tutorials/introduction/linux_install/linux_install.html - sudo apt-get install -y build-essential - sudo apt-get install -y cmake git libgtk2.0-dev pkg-config libavcodec-dev libavformat-dev libswscale-dev - sudo apt-get install -y python-dev python-numpy libtbb2 libtbb-dev libjpeg-dev libpng-dev libtiff-dev libjasper-dev libdc1394-22-dev # Download v3.1.0 .zip file and extract. - curl -sL https://github.com/Itseez/opencv/archive/3.1.0.zip &gt; opencv.zip - unzip -n opencv.zip &gt; log1 # Download EXTRA MODULES and extract. - curl -sL https://github.com/Itseez/opencv_contrib/archive/3.1.0.zip &gt; opencv_contrib.zip - unzip -n opencv_contrib.zip &gt; log2 # Create a new 'build' folder. - cd opencv-3.1.0 - mkdir -p build - cd build # if Makefile is cached, then skip cmake opencv # Set build instructions for Ubuntu distro. - cat Makefile &gt; l1 || cmake -D OPENCV_EXTRA_MODULES_PATH=../../opencv_contrib-3.1.0/modules CMAKE_BUILD_TYPE=RELEASE -D CMAKE_INSTALL_PREFIX=/usr/local -D WITH_TBB=ON -D BUILD_NEW_PYTHON_SUPPORT=ON -D WITH_V4L=ON -D INSTALL_C_EXAMPLES=ON -D INSTALL_PYTHON_EXAMPLES=ON -D BUILD_EXAMPLES=ON -D WITH_QT=ON -D WITH_OPENGL=ON .. # if Makefile is cached, then skip make opencv # Run 'make' with four threads. - cat Makefile &gt; l2 ||make -j5 &gt; make_log # Install to OS. - sudo make install # Add configuration to OpenCV to tell it where the library files are located on the file system (/usr/local/lib) - sudo sh -c 'echo\"/usr/local/lib\"&gt; /etc/ld.so.conf.d/opencv.conf' - sudo ldconfig - echo \"OpenCV installed.\" # We need to return to the repo \"root\" folder, so we can then 'cd' into the C++ project folder. - cd ../../ - ls -al script: - cmake CMakeLists.txt - make - \"./a.out &gt; log1.txt\"","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://ssarcandy.tw/tags/note/"},{"name":"opencv","slug":"opencv","permalink":"https://ssarcandy.tw/tags/opencv/"},{"name":"cmake","slug":"cmake","permalink":"https://ssarcandy.tw/tags/cmake/"}],"keywords":[]}]}